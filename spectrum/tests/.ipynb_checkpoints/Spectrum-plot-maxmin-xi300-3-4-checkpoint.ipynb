{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f01e95d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/local/scratch/kchan76/sparse-coarse-operator/spectrum/tests\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/scratch/kchan76/sparse-stencil-learning/src/pyamg2/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda:1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "import sys\n",
    "sys.path.append('/local/scratch/kchan76/sparse-coarse-operator/')\n",
    "from libs.pde import *\n",
    "from libs.rotated_laplacian import RotatedLaplacian\n",
    "from libs.models import BasicNet, MultiHeadedAttention\n",
    "from libs.utils import *\n",
    "import torch\n",
    "\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "print('device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "565291d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization\n",
    "list_eps = [1/300]\n",
    "low_pi = 3\n",
    "high_pi = 4\n",
    "theta_low = np.pi/12*low_pi\n",
    "theta_high = np.pi/12*high_pi\n",
    "# 10 points: xi = 300, 6-7\n",
    "npts = 5\n",
    "list_theta = np.linspace(theta_low, theta_high, npts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e916073",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_grid_size = 31\n",
    "k2 = 10\n",
    "k3 = 10\n",
    "same_vecs = False\n",
    "PDE = RotatedLaplacian(train_grid_size,[k2,k3],list_eps, list_theta,'fixed xi',same_vecs=same_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a07c54e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Model\n",
    "MODEL_DIR = f\"./../../models/laplacian/fixed-xi/xi-{int(1/list_eps[0])}/theta-{low_pi}pi\\\\12-{high_pi}pi\\\\12/\"\n",
    "model_prob2=torch.load(MODEL_DIR+\"level2_prob.pt\")\n",
    "model_value2=torch.load(MODEL_DIR+\"level2_value.pt\")\n",
    "model_prob3=torch.load(MODEL_DIR+\"level3_prob.pt\")\n",
    "model_value3 = torch.load(MODEL_DIR+\"level3_value.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "353e81a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test seed: 2\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MultiHeadedAttention' object has no attribute 'act'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [5], line 22\u001b[0m\n\u001b[1;32m     20\u001b[0m random_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     21\u001b[0m softmax_topk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m num_iter_standard, num_iter_learning, thetaList, _, _ \u001b[38;5;241m=\u001b[39m \u001b[43mPDE\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m                                                        \u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m                                                        \u001b[49m\u001b[43mtest_grid_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m                                                        \u001b[49m\u001b[43mmax_levels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m                                                        \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m                                                        \u001b[49m\u001b[43mtheta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m                                                        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m                                                        \u001b[49m\u001b[43mrandom_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m                                                        \u001b[49m\u001b[43msingle_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m                                                        \u001b[49m\u001b[43msoftmax_on\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msoftmax_topk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m                                                        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/local/scratch/kchan76/sparse-coarse-operator/libs/rotated_laplacian.py:242\u001b[0m, in \u001b[0;36mRotatedLaplacian.test_model\u001b[0;34m(self, num_test, models, test_grid_size, max_levels, epsilon, theta, device, dropout_on, random_test, single_model, softmax_on, top_accel, verbose)\u001b[0m\n\u001b[1;32m    232\u001b[0m solver_standard \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgeometric_solver(A,\n\u001b[1;32m    233\u001b[0m                                         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstandard\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    234\u001b[0m                                         models,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    239\u001b[0m                                         softmax_on\u001b[38;5;241m=\u001b[39msoftmax_on,\n\u001b[1;32m    240\u001b[0m                                         coarse_solver\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msplu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    241\u001b[0m \u001b[38;5;66;03m# assert 0 == 1 \u001b[39;00m\n\u001b[0;32m--> 242\u001b[0m solver_non_galerkin \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgeometric_solver\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[43m                                            \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlearning\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mtest_grid_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mdropout_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdropout_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mmax_levels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_levels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mcoarse_solver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msplu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43msingle_model\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msingle_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43msoftmax_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msoftmax_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    253\u001b[0m x0 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mones((A\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m],\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m    254\u001b[0m b \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrand(A\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m],\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/local/scratch/kchan76/sparse-coarse-operator/libs/rotated_laplacian.py:393\u001b[0m, in \u001b[0;36mRotatedLaplacian.geometric_solver\u001b[0;34m(self, A, option1, models, n, presmoother, postsmoother, max_levels, max_coarse, dropout_on, coarse_solver, device, single_model, softmax_on, **kwargs)\u001b[0m\n\u001b[1;32m    390\u001b[0m levels[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mn \u001b[38;5;241m=\u001b[39m n\n\u001b[1;32m    392\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(levels) \u001b[38;5;241m<\u001b[39m max_levels \u001b[38;5;129;01mand\u001b[39;00m levels[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mA\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m>\u001b[39m max_coarse:\n\u001b[0;32m--> 393\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextend_hierarchy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlevels\u001b[49m\u001b[43m,\u001b[49m\u001b[43moption1\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msingle_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msoftmax_on\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdropout_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdropout_on\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    395\u001b[0m ml \u001b[38;5;241m=\u001b[39m multilevel_solver(levels, coarse_solver\u001b[38;5;241m=\u001b[39mcoarse_solver)\n\u001b[1;32m    396\u001b[0m change_smoothers(ml, presmoother, postsmoother)\n",
      "File \u001b[0;32m/local/scratch/kchan76/sparse-coarse-operator/libs/rotated_laplacian.py:442\u001b[0m, in \u001b[0;36mRotatedLaplacian.extend_hierarchy\u001b[0;34m(self, levels, option1, models, device, single_model, softmax_on, dropout_on)\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[38;5;66;03m#             if level_num != 3:\u001b[39;00m\n\u001b[1;32m    441\u001b[0m             \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 442\u001b[0m                 prob \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_prob\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstencil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdouble\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[1;32m    443\u001b[0m                 value \u001b[38;5;241m=\u001b[39m model_value(stencil\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39mdouble())\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[1;32m    444\u001b[0m             XX \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msparsify(prob,value,single_model,softmax_on)\n",
      "File \u001b[0;32m/local/scratch/kchan76/sparse-stencil-learning/src/pyamg2/lib/python3.8/site-packages/torch/nn/modules/module.py:1051\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1047\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1052\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1053\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/local/scratch/kchan76/sparse-coarse-operator/libs/models.py:109\u001b[0m, in \u001b[0;36mMultiHeadedAttention.forward\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m    107\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mrepeat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mncopy,\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    108\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(x)\n\u001b[0;32m--> 109\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mact\u001b[49m(x)\n\u001b[1;32m    110\u001b[0m query, key, value \u001b[38;5;241m=\u001b[39m x, x, x\n\u001b[1;32m    111\u001b[0m nbatches \u001b[38;5;241m=\u001b[39m query\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m/local/scratch/kchan76/sparse-stencil-learning/src/pyamg2/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1128\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1130\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1131\u001b[0m     \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, name))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'MultiHeadedAttention' object has no attribute 'act'"
     ]
    }
   ],
   "source": [
    "# generate additional data points\n",
    "'''\n",
    "seed for  2-3.   3-4.   6-7 (3-level)\n",
    "100.      65(20) 14.    49\n",
    "200       13     15     30(doesn't work well here, use xi200.ipynb)\n",
    "300       4      2      17\n",
    "400       27     1(20)  10\n",
    "'''\n",
    "test_seed = 2\n",
    "set_global_seed(test_seed)\n",
    "print('test seed:', test_seed)\n",
    "num_test = 10\n",
    "models = {}\n",
    "models['level2'] = model_prob2, model_value2\n",
    "models['level3'] = model_prob3, model_value3\n",
    "max_levels = 3\n",
    "test_grid_size = 255\n",
    "epsilon = tuple(list_eps)\n",
    "theta = (theta_low, theta_high)\n",
    "random_test = True\n",
    "softmax_topk = False\n",
    "num_iter_standard, num_iter_learning, thetaList, _, _ = PDE.test_model(num_test,\n",
    "                                                        models,\n",
    "                                                        test_grid_size,\n",
    "                                                        max_levels,\n",
    "                                                        epsilon,\n",
    "                                                        theta,\n",
    "                                                        device,\n",
    "                                                        random_test=random_test,\n",
    "                                                        single_model= False,\n",
    "                                                        softmax_on = softmax_topk,\n",
    "                                                        verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bbe03552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[249, 312, 233, 251, 250, 270, 296, 213, 277, 276]\n",
      "[226, 233, 228, 218, 214, 213, 242, 207, 197, 204]\n",
      "[0.8995413618617749, 0.792185635017929, 0.9292994636022578, 0.8993652992801741, 0.8954501966344269, 0.8718796173050041, 0.8389750505024876, 0.9475229232698397, 0.8638475735165924, 0.855253380667494]\n"
     ]
    }
   ],
   "source": [
    "print(num_iter_standard)\n",
    "print(num_iter_learning)\n",
    "print(thetaList)\n",
    "iter_diff = [num_iter_learning[i]-num_iter_standard[i] for i in range(len(num_iter_standard))]\n",
    "min_index = iter_diff.index(min(iter_diff))\n",
    "# min_index = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "82840e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_index = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c179acc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse.linalg import eigs\n",
    "from pyamg.gallery import stencil_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fb57e5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# backup = [eigval2,eigval3]\n",
    "# eigval2 = backup[0]\n",
    "# eigval3 = backup[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c2d583d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3)\n",
      "(3, 3)\n",
      "(961, 961)\n",
      "(225, 225)\n",
      "torch.Size([3, 3])\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(2209, 2209)\n",
      "(529, 529)\n",
      "torch.Size([3, 3])\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(3969, 3969)\n",
      "(961, 961)\n",
      "torch.Size([3, 3])\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "(9025, 9025)\n",
      "(2209, 2209)\n",
      "torch.Size([3, 3])\n"
     ]
    },
    {
     "ename": "ArpackNoConvergence",
     "evalue": "ARPACK error -1: No convergence (22091 iterations, 0/1 eigenvectors converged) [ARPACK error -14: DNAUPD  did not find any eigenvalues to sufficient accuracy.]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mArpackNoConvergence\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [38], line 51\u001b[0m\n\u001b[1;32m     49\u001b[0m e2min,_ \u001b[38;5;241m=\u001b[39m eigs(Ac2, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, M \u001b[38;5;241m=\u001b[39m Ag2, which\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSM\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     50\u001b[0m e3max,_ \u001b[38;5;241m=\u001b[39m eigs(Ac3, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, M \u001b[38;5;241m=\u001b[39m Ag3, which\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLM\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 51\u001b[0m e3min,_ \u001b[38;5;241m=\u001b[39m \u001b[43meigs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mAc3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mM\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mAg3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhich\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSM\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m eigval2[n] \u001b[38;5;241m=\u001b[39m [e2max[\u001b[38;5;241m0\u001b[39m],e2min[\u001b[38;5;241m0\u001b[39m]]\n\u001b[1;32m     53\u001b[0m eigval3[n] \u001b[38;5;241m=\u001b[39m [e3max[\u001b[38;5;241m0\u001b[39m],e3min[\u001b[38;5;241m0\u001b[39m]]\n",
      "File \u001b[0;32m/local/scratch/kchan76/sparse-stencil-learning/src/pyamg2/lib/python3.8/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py:1345\u001b[0m, in \u001b[0;36meigs\u001b[0;34m(A, k, M, sigma, which, v0, ncv, maxiter, tol, return_eigenvectors, Minv, OPinv, OPpart)\u001b[0m\n\u001b[1;32m   1343\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _ARPACK_LOCK:\n\u001b[1;32m   1344\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m params\u001b[38;5;241m.\u001b[39mconverged:\n\u001b[0;32m-> 1345\u001b[0m         \u001b[43mparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1347\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m params\u001b[38;5;241m.\u001b[39mextract(return_eigenvectors)\n",
      "File \u001b[0;32m/local/scratch/kchan76/sparse-stencil-learning/src/pyamg2/lib/python3.8/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py:755\u001b[0m, in \u001b[0;36m_UnsymmetricArpackParams.iterate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    753\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    754\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 755\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_no_convergence\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    756\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    757\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ArpackError(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo, infodict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterate_infodict)\n",
      "File \u001b[0;32m/local/scratch/kchan76/sparse-stencil-learning/src/pyamg2/lib/python3.8/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py:375\u001b[0m, in \u001b[0;36m_ArpackParams._raise_no_convergence\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    373\u001b[0m     vec \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn, \u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m    374\u001b[0m     k_ok \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 375\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m ArpackNoConvergence(msg \u001b[38;5;241m%\u001b[39m (num_iter, k_ok, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk), ev, vec)\n",
      "\u001b[0;31mArpackNoConvergence\u001b[0m: ARPACK error -1: No convergence (22091 iterations, 0/1 eigenvectors converged) [ARPACK error -14: DNAUPD  did not find any eigenvalues to sufficient accuracy.]"
     ]
    }
   ],
   "source": [
    "# # create directory\n",
    "# MODEL_DIR = f\"./spectrum/data/laplacian/fixed-xi/xi-{int(1/list_eps[0])}/theta-{low_pi}pi\\\\12-{high_pi}pi\\\\12/\"\n",
    "# if not os.path.isdir(MODEL_DIR):\n",
    "#     os.makedirs(MODEL_DIR)\n",
    "# initialize dictionary\n",
    "eigval2 = {}\n",
    "eigval3 = {}\n",
    "sizes = [63,95,127,191,255,383,511]\n",
    "\n",
    "# iterate through different sizes\n",
    "for n in sizes:\n",
    "    n2 = n//2\n",
    "    n3 = (n//2)//2\n",
    "    model_prob2, model_value2, model_prob3, model_value3 = model_prob2.to(device), model_value2.to(device),model_prob3.to(device), model_value3.to(device)\n",
    "    theta = thetaList[min_index]\n",
    "    eps = list_eps[0]\n",
    "    _, _, s2, s3, _, _ = PDE.gen_data_point(31,[10,10],eps,theta)\n",
    "    print(s2.shape)\n",
    "    print(s2.shape)\n",
    "    Ag2 = stencil_grid(s2,(n2,n2))\n",
    "    Ag3 = stencil_grid(s3,(n3,n3))\n",
    "    print(Ag2.shape)\n",
    "    print(Ag3.shape)\n",
    "\n",
    "\n",
    "    single_model = False\n",
    "    softmax_on = False\n",
    "\n",
    "    stencil2 = torch.Tensor(s2).reshape(9,1)\n",
    "    stencil2 = torch.cat([stencil2[0:4],stencil2[5:9]]).t().to(device).double()\n",
    "    prob2 = model_prob2(stencil2).squeeze()\n",
    "    value2 = model_value2(stencil2).squeeze()\n",
    "    c2 = PDE.sparsify(prob2,value2,single_model,softmax_on).squeeze()\n",
    "    print(c2.shape) # (3,3)\n",
    "    c2 = c2.detach().cpu().numpy()\n",
    "\n",
    "    stencil3 = torch.Tensor(s3).reshape(9,1)\n",
    "    stencil3 = torch.cat([stencil3[0:4],stencil3[5:9]]).t().to(device).double()\n",
    "    prob3 = model_prob3(stencil3).squeeze()\n",
    "    value3 = model_value3(stencil3).squeeze()\n",
    "    c3 = PDE.sparsify(prob3,value3,single_model,softmax_on).squeeze()\n",
    "    c3 = c3.detach().cpu().numpy()\n",
    "\n",
    "    Ac2 = stencil_grid(c2,(n2,n2))\n",
    "    Ac3 = stencil_grid(c3,(n3,n3))\n",
    "    \n",
    "    # compute eigenvalues\n",
    "    e2max,_ = eigs(Ac2, k=1, M = Ag2, which='LM')\n",
    "    e2min,_ = eigs(Ac2, k=1, M = Ag2, which='SM')\n",
    "    e3max,_ = eigs(Ac3, k=1, M = Ag3, which='LM')\n",
    "    e3min,_ = eigs(Ac3, k=1, M = Ag3, which='SM')\n",
    "    eigval2[n] = [e2max[0],e2min[0]]\n",
    "    eigval3[n] = [e3max[0],e3min[0]]\n",
    "    \n",
    "#     # save eigenvalues\n",
    "#     file_name2 = MODEL_DIR + \"l2-n-\" + str(n) + \"-eigvals.npy\"\n",
    "#     file_name3 = MODEL_DIR + \"l3-n-\" + str(n) + \"-eigvals.npy\"\n",
    "#     np.save(file_name2, eigval2[n])\n",
    "#     np.save(file_name3, eigval3[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f022a057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create directory\n",
    "MODEL_DIR1 = f\"./spectrum/data/laplacian/fixed-xi/xi-{int(1/list_eps[0])}/theta-{low_pi}pi\\\\12-{high_pi}pi\\\\12/\"\n",
    "if not os.path.isdir(MODEL_DIR1):\n",
    "    os.makedirs(MODEL_DIR1)\n",
    "\n",
    "# save eigenvalues\n",
    "file_name2 = MODEL_DIR1 + \"l2-eigvals.npy\"\n",
    "file_name3 = MODEL_DIR1 + \"l3-eigvals.npy\"\n",
    "np.save(file_name2, eigval2)\n",
    "np.save(file_name3, eigval3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e50eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "evals2 = eigval2.values()\n",
    "# evals2_max = np.absolute(list(list(zip(*evals2))[0]))\n",
    "# evals2_min = np.absolute(list(list(zip(*evals2))[1]))\n",
    "evals2_max = list(list(zip(*evals2))[0])\n",
    "evals2_min = list(list(zip(*evals2))[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538fb769",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = f\"./spectrum/figs/laplacian/fixed-xi/xi-{int(1/list_eps[0])}/\"\n",
    "if not os.path.isdir(MODEL_DIR):\n",
    "    os.makedirs(MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8006b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "sizes = [63,95,127,191,255,383,511]\n",
    "title_name = \"Level 2, ξ = %d, θ = %.4f\"%(1/list_eps[0],theta)\n",
    "\n",
    "fig = plt.figure(dpi=300)\n",
    "plt.plot(sizes,evals2_max, 'v',markersize=8, label = 'Max', color = \"royalblue\")\n",
    "plt.plot(sizes,evals2_min, '^',markersize=8, label = 'Min', color = \"indianred\")\n",
    "for n in sizes:\n",
    "    plt.plot([n,n],[eigval2[n][0],eigval2[n][1]], '--k',lw=1)\n",
    "plt.legend()\n",
    "plt.ylim([0,8])\n",
    "plt.xticks(sizes)\n",
    "plt.xlabel(\"Mesh size\")\n",
    "plt.ylabel(\"Eigenvalue\")\n",
    "plt.title(title_name)\n",
    "file_name = MODEL_DIR + f\"theta-{low_pi}pi\\\\12-{high_pi}pi\\\\12_level2.png\"\n",
    "plt.savefig(file_name)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7ce882",
   "metadata": {},
   "outputs": [],
   "source": [
    "evals3 = eigval3.values()\n",
    "evals3_max = list(list(zip(*evals3))[0])\n",
    "evals3_min = list(list(zip(*evals3))[1])\n",
    "\n",
    "\n",
    "sizes = [63,95,127,191,255,383,511]\n",
    "title_name = \"Level 3, ξ = %d, θ = %.4f\"%(1/list_eps[0],theta)\n",
    "\n",
    "fig = plt.figure(dpi=300)\n",
    "plt.plot(sizes,evals3_max, 'v',markersize=8, label = 'Max', color = \"royalblue\")\n",
    "plt.plot(sizes,evals3_min, '^',markersize=8, label = 'Min', color = \"indianred\")\n",
    "plt.legend()\n",
    "for i in range(len(sizes)):\n",
    "    plt.plot([sizes[i],sizes[i]],[evals3_min[i],evals3_max[i]], '--k',lw=1)\n",
    "\n",
    "plt.ylim([0,12])\n",
    "plt.xticks(sizes)\n",
    "plt.xlabel(\"Mesh size\")\n",
    "plt.ylabel(\"Eigenvalue\")\n",
    "plt.title(title_name)\n",
    "file_name = MODEL_DIR + f\"theta-{low_pi}pi\\\\12-{high_pi}pi\\\\12_level3.png\"\n",
    "plt.savefig(file_name)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f454ca0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
