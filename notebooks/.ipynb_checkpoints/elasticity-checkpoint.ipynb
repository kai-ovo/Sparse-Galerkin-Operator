{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 697,
     "status": "ok",
     "timestamp": 1656897509194,
     "user": {
      "displayName": "Ru Huang",
      "userId": "03213243881794485520"
     },
     "user_tz": 240
    },
    "id": "j3sP_S_UjeZT"
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "dlopen(/Users/changkai/opt/anaconda3/lib/python3.9/site-packages/scipy/sparse/linalg/isolve/_iterative.cpython-39-darwin.so, 0x0002): Library not loaded: @rpath/libopenblas.dylib\n  Referenced from: /Users/changkai/opt/anaconda3/lib/python3.9/site-packages/scipy/sparse/linalg/isolve/_iterative.cpython-39-darwin.so\n  Reason: tried: '/Users/changkai/opt/anaconda3/lib/python3.9/site-packages/scipy/sparse/linalg/isolve/../../../../../../libopenblas.dylib' (no such file), '/Users/changkai/opt/anaconda3/lib/python3.9/site-packages/scipy/sparse/linalg/isolve/../../../../../../libopenblas.dylib' (no such file), '/Users/changkai/opt/anaconda3/bin/../lib/libopenblas.dylib' (no such file), '/Users/changkai/opt/anaconda3/bin/../lib/libopenblas.dylib' (no such file), '/usr/local/lib/libopenblas.dylib' (no such file), '/usr/lib/libopenblas.dylib' (no such file)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograd\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Variable\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# import higher\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyamg\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmultilevel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m multilevel_solver\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyamg\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrelaxation\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msmoothing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m change_smoothers\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m csr_matrix, isspmatrix_csr, SparseEfficiencyWarning\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pyamg/__init__.py:11\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m version_tuple \u001b[38;5;28;01mas\u001b[39;00m __version_tuple__\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m version \u001b[38;5;28;01mas\u001b[39;00m __version__\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (aggregation, amg_core, classical, gallery, krylov, relaxation, util, vis)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (blackbox, graph, graph_ref, multilevel, strength)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmultilevel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m coarse_grid_solver, multilevel_solver, MultilevelSolver\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pyamg/aggregation/__init__.py:3\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"Aggregation-based AMG.\"\"\"\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01madaptive\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m adaptive_sa_solver\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maggregate\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (standard_aggregation, naive_aggregation,\n\u001b[1;32m      5\u001b[0m                         lloyd_aggregation, balanced_lloyd_aggregation)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maggregation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m smoothed_aggregation_solver\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pyamg/aggregation/adaptive.py:9\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m csr_matrix, bsr_matrix, isspmatrix_csr,\\\n\u001b[1;32m      7\u001b[0m     isspmatrix_csc, isspmatrix_bsr, eye, SparseEfficiencyWarning\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmultilevel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MultilevelSolver\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstrength\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m symmetric_strength_of_connection,\\\n\u001b[1;32m     11\u001b[0m     classical_strength_of_connection, evolution_strength_of_connection\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkrylov\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m gmres\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pyamg/multilevel.py:6\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m warn\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msp\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinalg\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msla\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinalg\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LinearOperator\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/scipy/sparse/linalg/__init__.py:111\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03mSparse linear algebra (:mod:`scipy.sparse.linalg`)\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m==================================================\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    108\u001b[0m \n\u001b[1;32m    109\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 111\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01misolve\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdsolve\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minterface\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/scipy/sparse/linalg/isolve/__init__.py:4\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIterative Solvers for Sparse Linear Systems\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#from info import __doc__\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01miterative\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mminres\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m minres\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlgmres\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m lgmres\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/scipy/sparse/linalg/isolve/iterative.py:8\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _iterative\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinalg\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minterface\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LinearOperator\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m make_system\n",
      "\u001b[0;31mImportError\u001b[0m: dlopen(/Users/changkai/opt/anaconda3/lib/python3.9/site-packages/scipy/sparse/linalg/isolve/_iterative.cpython-39-darwin.so, 0x0002): Library not loaded: @rpath/libopenblas.dylib\n  Referenced from: /Users/changkai/opt/anaconda3/lib/python3.9/site-packages/scipy/sparse/linalg/isolve/_iterative.cpython-39-darwin.so\n  Reason: tried: '/Users/changkai/opt/anaconda3/lib/python3.9/site-packages/scipy/sparse/linalg/isolve/../../../../../../libopenblas.dylib' (no such file), '/Users/changkai/opt/anaconda3/lib/python3.9/site-packages/scipy/sparse/linalg/isolve/../../../../../../libopenblas.dylib' (no such file), '/Users/changkai/opt/anaconda3/bin/../lib/libopenblas.dylib' (no such file), '/Users/changkai/opt/anaconda3/bin/../lib/libopenblas.dylib' (no such file), '/usr/local/lib/libopenblas.dylib' (no such file), '/usr/lib/libopenblas.dylib' (no such file)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from importlib import reload\n",
    "from itertools import product\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "import pyamg\n",
    "import random\n",
    "import math\n",
    "from torch.autograd import Variable\n",
    "# import higher\n",
    "from pyamg.multilevel import multilevel_solver\n",
    "from pyamg.relaxation.smoothing import change_smoothers\n",
    "from scipy.sparse import csr_matrix, isspmatrix_csr, SparseEfficiencyWarning\n",
    "\n",
    "\n",
    "from collections import defaultdict\n",
    "from functools import lru_cache\n",
    "import collections\n",
    "\n",
    "from scipy.sparse import coo_matrix,csr_matrix, isspmatrix_csr, SparseEfficiencyWarning\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from pyamg.aggregation.tentative import fit_candidates\n",
    "from pyamg.aggregation import jacobi_prolongation_smoother,richardson_prolongation_smoother, energy_prolongation_smoother\n",
    "from pyamg.aggregation.aggregate import standard_aggregation, naive_aggregation,\\\n",
    "    lloyd_aggregation\n",
    "from pyamg.util.utils import get_blocksize\n",
    "from pyamg.strength import classical_strength_of_connection,\\\n",
    "    symmetric_strength_of_connection, evolution_strength_of_connection,\\\n",
    "    energy_based_strength_of_connection, distance_strength_of_connection,\\\n",
    "    algebraic_distance, affinity_distance\n",
    "import scipy\n",
    "from scipy.sparse import csr_matrix, lil_matrix\n",
    "from scipy.sparse.csgraph import laplacian as csgraph_laplacian\n",
    "from scipy.spatial.qhull import Delaunay\n",
    "from sklearn import datasets\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device = 'cpu'\n",
    "#Parameters\n",
    "#Two classes of problems, rotated laplacian and graph clustering\n",
    "Problem = 'rotated'\n",
    "train_grid_size = 15\n",
    "\n",
    "# Problem = 'graph clustering'\n",
    "# train_num_points = 32\n",
    "# test_num_points = 32\n",
    "\n",
    "num_eigenvecs = 100   #number of eigenvecs in loss function\n",
    "feature_dims = 10    #the dimension of the features X, also the max number of nonzeros in each row.\n",
    "epochs = 10000       #number of training epochs     \n",
    "num_batch = 16     #batch size\n",
    "num_train = 30     #number of training examples\n",
    "num_test = 1\n",
    "up = 2.01\n",
    "low = -1.01\n",
    "learning_rate = 0.001  #learning rate\n",
    "import collections\n",
    "def diffusion_stencil_2d(epsilon=1.0, theta=0.0, type='FE'):\n",
    "    eps = float(epsilon)  # for brevity\n",
    "    theta = float(theta)\n",
    "\n",
    "    C = np.cos(theta)\n",
    "    S = np.sin(theta)\n",
    "    CS = C*S\n",
    "    CC = C**2\n",
    "    SS = S**2\n",
    "\n",
    "    if(type == 'FE'):\n",
    "        a = (-1*eps - 1)*CC + (-1*eps - 1)*SS + (3*eps - 3)*CS\n",
    "        b = (2*eps - 4)*CC + (-4*eps + 2)*SS\n",
    "        c = (-1*eps - 1)*CC + (-1*eps - 1)*SS + (-3*eps + 3)*CS\n",
    "        d = (-4*eps + 2)*CC + (2*eps - 4)*SS\n",
    "        e = (8*eps + 8)*CC + (8*eps + 8)*SS\n",
    "\n",
    "        stencil = np.array([[a, b, c],\n",
    "                            [d, e, d],\n",
    "                            [c, b, a]]) / 6.0\n",
    "\n",
    "    elif type == 'FD':\n",
    "\n",
    "        a = -0.5*(eps - 1)*CS\n",
    "        b = -(eps*SS + CC)\n",
    "        c = -a\n",
    "        d = -(eps*CC + SS)\n",
    "        e = 2.0*(eps + 1)\n",
    "\n",
    "        stencil = np.array([[a+c, d-2*c, 2*c],\n",
    "                            [b-2*c, e+4*c, b-2*c],\n",
    "                            [2*c, d-2*c, a+c]])\n",
    "\n",
    "        \n",
    "    return stencil\n",
    "def map_2_to_1(grid_size_x=8,grid_size_y=8,stencil_size=3):\n",
    "    # maps 2D coordinates to the corresponding 1D coordinate in the matrix.\n",
    "    k = np.zeros((grid_size_x, grid_size_y, stencil_size, stencil_size))\n",
    "    M = np.reshape(np.arange(grid_size_x * grid_size_y), (grid_size_x, grid_size_y))\n",
    "    M = np.concatenate([M, M], 0)\n",
    "    M = np.concatenate([M, M], 1)\n",
    "    for i in range(stencil_size):\n",
    "        I = (i - stencil_size//2) % grid_size_x\n",
    "        for j in range(stencil_size):\n",
    "            J = (j - stencil_size//2) % grid_size_y\n",
    "            k[:, :, i, j] = M[I:I + grid_size_x, J:J + grid_size_y]\n",
    "    return k\n",
    "def get_p_matrix_indices_one(grid_size):\n",
    "    K = map_2_to_1(grid_size=grid_size)\n",
    "    indices = []\n",
    "    for ic in range(grid_size // 2):\n",
    "        i = 2 * ic + 1\n",
    "        for jc in range(grid_size // 2):\n",
    "            j = 2 * jc + 1\n",
    "            J = int(grid_size // 2 * jc + ic)\n",
    "            for k in range(3):\n",
    "                for m in range(3):\n",
    "                    I = int(K[i, j, k, m])\n",
    "                    indices.append([I, J])\n",
    "\n",
    "    return np.array(indices)\n",
    "\n",
    "def compute_stencil(A, grid_size_x,grid_size_y,stencil_size):\n",
    "    indices = get_indices_compute_A_one(grid_size_x,grid_size_y,stencil_size)\n",
    "    stencil = np.array(A[indices[:, 0], indices[:, 1]]).reshape((grid_size_x, grid_size_y, stencil_size, stencil_size))\n",
    "    return stencil\n",
    "def get_indices_compute_A_one(grid_size_x=8,grid_size_y=8,stencil_size=3):\n",
    "    indices = []\n",
    "    K = map_2_to_1(grid_size_x,grid_size_y,stencil_size)\n",
    "    for i in range(grid_size_x):\n",
    "        for j in range(grid_size_y):\n",
    "            I = int(K[i, j, stencil_size//2, stencil_size//2])\n",
    "            for k in range(stencil_size):\n",
    "                for m in range(stencil_size):\n",
    "                    J = int(K[i, j, k, m])\n",
    "                    indices.append([I, J])\n",
    "\n",
    "    return np.array(indices)\n",
    "def compute_p2(P_stencil, grid_size):\n",
    "    indexes = get_p_matrix_indices_one(grid_size)\n",
    "    P = sp.sparse.csr_matrix(arg1=(P_stencil.reshape(-1), (indexes[:, 1], indexes[:, 0])),\n",
    "                   shape=((grid_size//2) ** 2, (grid_size) ** 2))\n",
    "\n",
    "    return P\n",
    "def compute_A_indices(grid_size_x=8,grid_size_y=8,stencil_size=3):\n",
    "    K = map_2_to_1(grid_size_x,grid_size_y,stencil_size)\n",
    "    A_idx = []\n",
    "    stencil_idx = []\n",
    "    for i in range(grid_size_x):\n",
    "        for j in range(grid_size_y):\n",
    "            I = int(K[i, j, stencil_size//2, stencil_size//2])\n",
    "            for k in range(stencil_size):\n",
    "                for m in range(stencil_size):\n",
    "                    J = int(K[i, j, k, m])\n",
    "                    A_idx.append([I, J])\n",
    "                    stencil_idx.append([i, j, k, m])\n",
    "    return np.array(A_idx), stencil_idx\n",
    "def compute_p2_old(P_stencil, grid_size):\n",
    "    indexes = get_p_matrix_indices_one_old(grid_size)\n",
    "    P = sp.sparse.csr_matrix(arg1=(P_stencil.reshape(-1), (indexes[:, 1], indexes[:, 0])),\n",
    "                   shape=((grid_size//2) ** 2, (grid_size) ** 2))\n",
    "\n",
    "    return P\n",
    "def get_p_matrix_indices_one_old(grid_size):\n",
    "    K = map_2_to_1_old(grid_size=grid_size)\n",
    "    indices = []\n",
    "    for ic in range(grid_size // 2):\n",
    "        i = 2 * ic + 1\n",
    "        for jc in range(grid_size // 2):\n",
    "            j = 2 * jc + 1\n",
    "            J = int(grid_size // 2 * jc + ic)\n",
    "            for k in range(3):\n",
    "                for m in range(3):\n",
    "                    I = int(K[i, j, k, m])\n",
    "                    indices.append([I, J])\n",
    "\n",
    "    return np.array(indices)\n",
    "def map_2_to_1_old(grid_size=8):\n",
    "    # maps 2D coordinates to the corresponding 1D coordinate in the matrix.\n",
    "    k = np.zeros((grid_size, grid_size, 3, 3))\n",
    "    M = np.reshape(np.arange(grid_size ** 2), (grid_size, grid_size))\n",
    "    M = np.concatenate([M, M], 0)\n",
    "    M = np.concatenate([M, M], 1)\n",
    "    for i in range(3):\n",
    "        I = (i - 1) % grid_size\n",
    "        for j in range(3):\n",
    "            J = (j - 1) % grid_size\n",
    "            k[:, :, i, j] = M[I:I + grid_size, J:J + grid_size]\n",
    "    return k\n",
    "\n",
    "# def prolongation_fn(grid_size):\n",
    "# #     grid_size = int(math.sqrt(A.shape[0]))\n",
    "#     res_stencil = np.double(np.zeros((3,3)))\n",
    "#     k=16\n",
    "#     res_stencil[0,0] = 1/k\n",
    "#     res_stencil[0,1] = 2/k\n",
    "#     res_stencil[0,2] = 1/k\n",
    "#     res_stencil[1,0] = 2/k\n",
    "#     res_stencil[1,1] = 4/k\n",
    "#     res_stencil[1,2] = 2/k\n",
    "#     res_stencil[2,0] = 1/k\n",
    "#     res_stencil[2,1] = 2/k\n",
    "#     res_stencil[2,2] = 1/k\n",
    "#     P_stencils= np.zeros((grid_size//2,grid_size//2,3,3))\n",
    "#     for i in range(grid_size//2):\n",
    "#         for j in range(grid_size//2):\n",
    "#             P_stencils[i,j,:,:]=res_stencil\n",
    "#     return compute_p2_old(P_stencils, grid_size).astype(np.double)  # imaginary part should be zero\n",
    "def compute_A(P_stencil, grid_size_x,grid_size_y,stencil_size):\n",
    "    A,indexes = compute_A_indices(grid_size_x,grid_size_y,stencil_size)\n",
    "    P = torch.sparse.DoubleTensor(torch.LongTensor(A.T), P_stencil.view(-1), (grid_size_x*grid_size_y,grid_size_x*grid_size_y))\n",
    "    return P\n",
    "def compute_A_old(P_stencil, grid_size_x,grid_size_y,stencil_size):\n",
    "    A,indexes = compute_A_indices(grid_size_x,grid_size_y,stencil_size)\n",
    "    P = torch.sparse.DoubleTensor(torch.LongTensor(A.T), P_stencil.view(-1), (grid_size_x*grid_size_y,grid_size_x*grid_size_y))\n",
    "    return P\n",
    "def compute_A_numpy(P_stencil, grid_size_x,grid_size_y,stencil_size):\n",
    "    A,indexes = compute_A_indices(grid_size_x,grid_size_y,stencil_size)\n",
    "    P = csr_matrix(arg1=(P_stencil.reshape((-1)), (A[:, 0], A[:, 1])),\n",
    "                              shape=(grid_size_x*grid_size_y,grid_size_x*grid_size_y))\n",
    "    return P\n",
    "\n",
    "def coo_to_tensor(coo):\n",
    "    values = coo.data\n",
    "    indices = np.vstack((coo.row, coo.col))\n",
    "    i = torch.LongTensor(indices)\n",
    "    v = torch.DoubleTensor(values)\n",
    "    shape = coo.shape\n",
    "    return torch.sparse.DoubleTensor(i, v, torch.Size(shape)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 343,
     "status": "ok",
     "timestamp": 1656897509535,
     "user": {
      "displayName": "Ru Huang",
      "userId": "03213243881794485520"
     },
     "user_tz": 240
    },
    "id": "KjEU_KnnMF5h"
   },
   "outputs": [],
   "source": [
    "def elasticity(E=1e-5,nu=0.3,by=1):\n",
    "    mu = E*(1+2*nu)\n",
    "    lam = E*nu/((1+nu)*(1-2*nu))\n",
    "    k17 = (-lam*by*by-2*mu*by*by+lam+mu)/(4*(2*lam*by*by+lam+4*(by*by+1)*mu))\n",
    "    k14 = -(2*lam*by*by+4*mu*by*by+lam+mu)/(2*(2*lam*by*by+lam+4*(by*by+1)*mu))\n",
    "    k11 = k17\n",
    "    k12 = ((by**2-1)*lam+2*(by**2-2)*mu)/(2*(2*lam*by*by+lam+4*(by**2+1)*mu))\n",
    "    k18 = k12\n",
    "    k15 = 1\n",
    "    k19 = k17\n",
    "    k13 = k17\n",
    "    k16 = k14\n",
    "    s1 = np.array([[k17,k18,k19],[k14,k15,k16],[k11,k12,k13]])\n",
    "    k = (3*by*(lam+mu))/(8*(2*lam*by*by+lam+4*(by*by+1)*mu))\n",
    "    s2 = np.array([[k,0,-k],[0,0,0],[-k,0,k]])\n",
    "    return s1,s2\n",
    "def transpose_stencil_numpy(s):\n",
    "    a = s[0,0]\n",
    "    b = s[0,1]\n",
    "    c = s[0,2]\n",
    "    d = s[1,0]\n",
    "    e = s[1,1]\n",
    "    f = s[1,2]\n",
    "    g = s[2,0]\n",
    "    h = s[2,1]\n",
    "    i = s[2,2]\n",
    "    return np.array([[i,h,g],[f,e,d],[c,b,a]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1656897509535,
     "user": {
      "displayName": "Ru Huang",
      "userId": "03213243881794485520"
     },
     "user_tz": 240
    },
    "id": "PNUNzjEzDS1q"
   },
   "outputs": [],
   "source": [
    "def reorder(X,option):\n",
    "    new_IDX = []\n",
    "    old_IDX = []\n",
    "    if len(X.shape)<3:\n",
    "        if option == 1:\n",
    "            m,n = X.shape\n",
    "            Y = torch.zeros(m,n).double()\n",
    "            IDX = []\n",
    "            for i in range(m):\n",
    "                for j in range(n):\n",
    "                    if (i%2)==(j%2):\n",
    "                        IDX.append((i,j))\n",
    "            for (i,j) in IDX:\n",
    "                new_i = (i+j)//2\n",
    "                new_j = (-i+j)//2+m//2\n",
    "                Y[new_i,new_j] = X[i,j]\n",
    "                new_IDX.append(new_i*n+new_j)        \n",
    "        else:\n",
    "            m,n = X.shape\n",
    "            Y = torch.zeros(m,n).double()\n",
    "            IDX = []\n",
    "            for i in range(m):\n",
    "                for j in range(n):\n",
    "                    if (i%2)!=(j%2):\n",
    "                        IDX.append((i,j))\n",
    "            for (i,j) in IDX:\n",
    "                new_i = (i+j)//2\n",
    "                new_j = (-i+j)//2+m//2\n",
    "                Y[new_i,new_j] = X[i,j]\n",
    "                new_IDX.append(new_i*n+new_j)\n",
    "    elif len(X.shape)==3:\n",
    "        z,m,n = X.shape\n",
    "        Y = torch.zeros(z,m,n).double()\n",
    "        for i in range(z):\n",
    "            Y[i,:,:] = reorder(X[i,:,:],1)[0]\n",
    "    return Y,new_IDX,old_IDX\n",
    "def reorder_T(X,option):\n",
    "    new_IDX=[]\n",
    "    old_IDX = []\n",
    "    if option == 1:\n",
    "        m,n = X.shape\n",
    "        Y = torch.zeros(m,n).double()\n",
    "        IDX = []\n",
    "        for i in range(m):\n",
    "            if i<=m//2:\n",
    "                for j in range(n//2-i,n//2+i+1):\n",
    "                    IDX.append((i,j))\n",
    "            else:\n",
    "                for j in range(n//2-m+i+1,n//2+m-i):\n",
    "                    IDX.append((i,j))\n",
    "        for (i,j) in IDX:\n",
    "            new_i = (i-j)+m//2\n",
    "            new_j = (i+j)-m//2\n",
    "            Y[new_i,new_j] = X[i,j]\n",
    "            new_IDX.append(new_i*n+new_j)\n",
    "            old_IDX.append(i*n+j)\n",
    "    elif option == 2:\n",
    "        m,n = X.shape\n",
    "        Y = torch.zeros(m,n).double()\n",
    "        IDX = []\n",
    "        for i in range(m):\n",
    "            if i<m//2:\n",
    "                for j in range(n//2-i-1,n//2+i+1):\n",
    "                    IDX.append((i,j))\n",
    "            elif i<(m//2)*2:\n",
    "                for j in range(n//2-m+i+1,n//2+m-i-1):\n",
    "                    IDX.append((i,j))\n",
    "\n",
    "        for (i,j) in IDX:\n",
    "            if 0<=i<m-1 and 0<=j<n-1:\n",
    "                new_i = (i-j)+m//2\n",
    "                new_j = (i+j)-m//2+1\n",
    "                # print((i,j),(new_i,new_j))\n",
    "                Y[new_i,new_j] = X[i,j]\n",
    "                new_IDX.append(new_i*n+new_j)\n",
    "                old_IDX.append(i*n+j)\n",
    "    return Y,new_IDX,old_IDX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1656897509535,
     "user": {
      "displayName": "Ru Huang",
      "userId": "03213243881794485520"
     },
     "user_tz": 240
    },
    "id": "EUygo66jX_mC"
   },
   "outputs": [],
   "source": [
    "res1_uu = np.zeros((3,3))\n",
    "res1_uu[0,1] = .25\n",
    "res1_uu[1,0] =  .25\n",
    "res1_uu[1,1] =  1\n",
    "res1_uu[1,2] =  .25\n",
    "res1_uu[2,1] =  .25\n",
    "\n",
    "res1_uv = np.zeros((3,3))\n",
    "res1_uv[0,1] = .25\n",
    "res1_uv[1,0] = -.25\n",
    "res1_uv[1,1] = 0\n",
    "res1_uv[1,2] = -.25\n",
    "res1_uv[2,1] = .25\n",
    "\n",
    "res1_vu = np.zeros((3,3))\n",
    "res1_vu[0,1] = -.25\n",
    "res1_vu[1,0] = .25\n",
    "res1_vu[1,1] = 0\n",
    "res1_vu[1,2] = .25\n",
    "res1_vu[2,1] = -.25\n",
    "\n",
    "res1_vv = np.zeros((3,3))\n",
    "res1_vv[0,1] =.25\n",
    "res1_vv[1,0] = .25\n",
    "res1_vv[1,1] = 1\n",
    "res1_vv[1,2] =.25\n",
    "res1_vv[2,1] = .25\n",
    "# res2_vv = np.zeros((3,3))\n",
    "# res2_vv[0,0] = .25\n",
    "# res2_vv[0,2] = .25\n",
    "# res2_vv[1,1] = 1\n",
    "# res2_vv[2,0] = .25\n",
    "# res2_vv[2,2] = .25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1656897509535,
     "user": {
      "displayName": "Ru Huang",
      "userId": "03213243881794485520"
     },
     "user_tz": 240
    },
    "id": "XtcDT_OQA0GB"
   },
   "outputs": [],
   "source": [
    "# n=15\n",
    "# A, B = pyamg.gallery.linear_elasticity((n, n))\n",
    "# A = A.tocsr()\n",
    "# Auu = A[n*n:,n*n:]\n",
    "# s = compute_stencil(Auu,n,n,7)\n",
    "# AA = compute_A(torch.from_numpy(s),n,n,7)\n",
    "# print(np.linalg.norm(Auu.toarray()-AA.to_dense().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1656897509536,
     "user": {
      "displayName": "Ru Huang",
      "userId": "03213243881794485520"
     },
     "user_tz": 240
    },
    "id": "ikytpMhsJYui"
   },
   "outputs": [],
   "source": [
    "# s1,s2 = elasticity(E=1e+1,nu=0.3,by=1)\n",
    "# s3 = transpose_stencil_numpy(s2)\n",
    "# s4 = transpose_stencil_numpy(s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1656897509536,
     "user": {
      "displayName": "Ru Huang",
      "userId": "03213243881794485520"
     },
     "user_tz": 240
    },
    "id": "oNDvEyHPCjXh"
   },
   "outputs": [],
   "source": [
    "# n = 9\n",
    "# Auu = pyamg.gallery.stencil_grid(s1,(n,n))\n",
    "# Auv = pyamg.gallery.stencil_grid(s2,(n,n))\n",
    "# Avu = pyamg.gallery.stencil_grid(s3,(n,n))\n",
    "# Avv = pyamg.gallery.stencil_grid(s4,(n,n))\n",
    "\n",
    "# A_uu_uv = scipy.sparse.hstack((Auu,Auv))\n",
    "# A_vu_vv = scipy.sparse.hstack((Avu,Avv))\n",
    "# A = scipy.sparse.vstack((A_uu_uv,A_vu_vv))\n",
    "\n",
    "\n",
    "# R1_uu_test = pyamg.gallery.stencil_grid(res1_uu,(n,n)).tocsr()\n",
    "# R1_uu = R1_uu_test[0:n*n:2,:]\n",
    "# P1_uu = R1_uu.T\n",
    "# P1_uu_test = R1_uu_test.T\n",
    "# # A_test = R1_test*Auu*P1_test\n",
    "# # stencil = compute_stencil(A_test,n,n,7)\n",
    "# # A_TT = compute_A(torch.from_numpy(stencil),n,n,7)\n",
    "# # print(np.linalg.norm(A_TT.to_dense().numpy()-A_test.toarray()))\n",
    "# # stencil = stencil[n//2,n//2,:,:]\n",
    "# # A_TT = pyamg.gallery.stencil_grid(stencil,(n,n))\n",
    "# # print(np.linalg.norm(A_TT.toarray()-A_test.toarray()))\n",
    "# # stencil = stencil[n//2,n//2,:,:]\n",
    "# I = scipy.sparse.csr_matrix(R1_uu_test.shape)\n",
    "# R1_uv_test = pyamg.gallery.stencil_grid(res1_uv,(n,n)).tocsr()\n",
    "# R1_uv = R1_uv_test[0:n*n:2,:]\n",
    "# P1_uv = R1_uv.T\n",
    "# P1_uv_test = R1_uv_test.T\n",
    "\n",
    "# R1_vu_test = pyamg.gallery.stencil_grid(res1_vu,(n,n)).tocsr()\n",
    "# R1_vu = R1_vu_test[0:n*n:2,:]\n",
    "# P1_vu = R1_vu.T\n",
    "# P1_vu_test = R1_vu_test.T\n",
    "\n",
    "# R1_vv_test = pyamg.gallery.stencil_grid(res1_vv,(n,n)).tocsr()\n",
    "# R1_vv = R1_vv_test[0:n*n:2,:]\n",
    "# P1_vv = R1_vv.T\n",
    "# P1_vv_test = R1_vv_test.T\n",
    "\n",
    "# II = scipy.sparse.csr_matrix(R1_uu.shape)\n",
    "# # R_uu_uv = scipy.sparse.hstack((R1_uu,R1_uv))\n",
    "# # R_vu_vv = scipy.sparse.hstack((R1_vu,R1_vv))\n",
    "# R_uu_uv = scipy.sparse.hstack((R1_uu,II))\n",
    "# R_vu_vv = scipy.sparse.hstack((II,R1_vv))\n",
    "\n",
    "# R = scipy.sparse.vstack((R_uu_uv,R_vu_vv))\n",
    "# P = R.T\n",
    "\n",
    "# R_uu_uv_test = scipy.sparse.hstack((R1_uu_test,R1_uv_test))\n",
    "# R_vu_vv_test = scipy.sparse.hstack((R1_vu_test,R1_vv_test))\n",
    "# # R_uu_uv_test = scipy.sparse.hstack((R1_uu_test,I))\n",
    "# # R_vu_vv_test = scipy.sparse.hstack((I,R1_vv_test))\n",
    "\n",
    "# R_test = scipy.sparse.vstack((R_uu_uv_test,R_vu_vv_test))\n",
    "# P_test = R_test.T\n",
    "\n",
    "# A_test = R_test*A*P_test\n",
    "# # A = R*A*P\n",
    "# A = A_test[0:n*n*2:2,]\n",
    "# A = A[:,0:n*n*2:2]\n",
    "\n",
    "# # A_test = A_test[0:n*n*2:2,:]\n",
    "# # A_test = A_test[:,0:n*n*2:2]\n",
    "# A_uu_test = A_test[0:n*n,0:n*n]\n",
    "# A_uv_test = A_test[0:n*n,n*n:]\n",
    "# A_vu_test = A_test[n*n:,0:n*n]\n",
    "# A_vv_test = A_test[n*n:,n*n:]\n",
    "\n",
    "# stencil_uu = compute_stencil(A_uu_test,n,n,7)\n",
    "# s = stencil_uu[n//2,n//2,:,:]\n",
    "# s,_,_ = reorder(s,1)\n",
    "# print(s)\n",
    "# s,_,_ = reorder_T(s,1)\n",
    "# for i in range(2,stencil_uu.shape[0]-2):\n",
    "#   for j in range(2,stencil_uu.shape[1]-2):\n",
    "#       stencil_uu[i,j,:,:]=s\n",
    "# A_TT_uu = compute_A(torch.from_numpy(stencil_uu),n,n,7)\n",
    "# print(np.linalg.norm(A_TT_uu.to_dense().numpy()-A_uu_test.toarray()))\n",
    "\n",
    "# stencil_uv = compute_stencil(A_uv_test,n,n,5)\n",
    "# s = stencil_uv[n//2,n//2,:,:]\n",
    "# s,_,_ = reorder(s,2)\n",
    "# print(s)\n",
    "\n",
    "# s,_,_ = reorder_T(s,2)\n",
    "# for i in range(2,stencil_uv.shape[0]-2):\n",
    "#   for j in range(2,stencil_uv.shape[1]-2):\n",
    "#       stencil_uv[i,j,:,:]=s\n",
    "# A_TT_uv = compute_A(torch.from_numpy(stencil_uv),n,n,5)\n",
    "# print(np.linalg.norm(A_TT_uv.to_dense().numpy()-A_uv_test.toarray()))\n",
    "\n",
    "# stencil_vu = compute_stencil(A_vu_test,n,n,5)\n",
    "# s = stencil_vu[n//2,n//2,:,:]\n",
    "# s,_,_ = reorder(s,2)\n",
    "# print(s)\n",
    "\n",
    "# s,_,_ = reorder_T(s,2)\n",
    "# for i in range(2,stencil_vu.shape[0]-2):\n",
    "#   for j in range(2,stencil_vu.shape[1]-2):\n",
    "#       stencil_vu[i,j,:,:]=s\n",
    "# A_TT_vu = compute_A(torch.from_numpy(stencil_vu),n,n,5)\n",
    "# print(np.linalg.norm(A_TT_vu.to_dense().numpy()-A_vu_test.toarray()))\n",
    "\n",
    "# stencil_vv = compute_stencil(A_vv_test,n,n,7)\n",
    "# s = stencil_vv[n//2,n//2,:,:]\n",
    "# s,_,_ = reorder(s,1)\n",
    "# print(s)\n",
    "\n",
    "# s,_,_ = reorder_T(s,1)\n",
    "# for i in range(2,stencil_vv.shape[0]-2):\n",
    "#   for j in range(2,stencil_vv.shape[1]-2):\n",
    "#       stencil_vv[i,j,:,:]=s\n",
    "\n",
    "# A_TT_vv = compute_A(torch.from_numpy(stencil_vv),n,n,7)\n",
    "# print(np.linalg.norm(A_TT_vv.to_dense().numpy()-A_vv_test.toarray()))\n",
    "\n",
    "\n",
    "# A11 = torch.hstack((A_TT_uu,A_TT_uv))\n",
    "# A12 = torch.hstack((A_TT_vu,A_TT_vv))\n",
    "# A_test = torch.vstack((A11,A12))\n",
    "# A_test = A_test.to_dense()\n",
    "# A_test = A_test[0:n*n*2:2,:]\n",
    "# A_test = A_test[:,0:n*n*2:2]\n",
    "# print(np.linalg.norm(A_test.numpy()-A.toarray()))\n",
    "\n",
    "# # stencil = compute_stencil(A,n,n,7)\n",
    "# # A_TT = compute_A(torch.from_numpy(stencil),n,n,7)\n",
    "# # print(np.linalg.norm(A_TT.to_dense().numpy()-A.toarray()))\n",
    "\n",
    "# # A_test = A_test[0:n*n:2,:]\n",
    "# # A_test = A_test[:,0:n*n:2]\n",
    "# # A = R1_uu*Auu*P1_uu\n",
    "# # print(np.linalg.norm(A_test.toarray()-A.toarray()))\n",
    "# # R2_uu = pyamg.gallery.stencil_grid(res2_uu,(n,n)).tocsr()\n",
    "# # #R = pyamg.gallery.stencil_grid(res2,(n,n)).toarray()\n",
    "# # R2_uu = R2_uu[0:n*n:2,:]\n",
    "# # R2_uu = R2_uu[:,0:n*n:2]\n",
    "# # idx = []\n",
    "# # for j in range(n//2+1):\n",
    "\n",
    "# #     idx = idx+list(range(j*n,j*n+n//2+1))\n",
    "# # R2_uu = R2_uu[idx,:]\n",
    "# # #         R = R[:,idx]\n",
    "# # P2_uu=R2_uu.T\n",
    "# # # print(Auu.sum(axis=1))\n",
    "# # A = R1_uu*Auu*P1_uu\n",
    "# # print(A.sum(axis=1))\n",
    "# # A = R2_uu*A*P2_uu\n",
    "# # print(A.sum(axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1656897509536,
     "user": {
      "displayName": "Ru Huang",
      "userId": "03213243881794485520"
     },
     "user_tz": 240
    },
    "id": "zicZEkgQs6Q_"
   },
   "outputs": [],
   "source": [
    "# s1,s2 =  elasticity()\n",
    "# s3 = transpose_stencil_numpy(s2)\n",
    "# s4 = transpose_stencil_numpy(s1)\n",
    "# print(s2.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1656897509536,
     "user": {
      "displayName": "Ru Huang",
      "userId": "03213243881794485520"
     },
     "user_tz": 240
    },
    "id": "mn3dlN3i97sR"
   },
   "outputs": [],
   "source": [
    "  # # import numpy as np\n",
    "  # # import pyamg\n",
    "  # eps = 0.01\n",
    "  # n = 15\n",
    "  # # theta = np.pi/6*np.random.rand(1).item()+np.pi/6\n",
    "  # theta = np.pi/4\n",
    "  # s = diffusion_stencil_2d(epsilon=eps, theta=theta, type='FD')\n",
    "  # A = pyamg.gallery.stencil_grid(s,(n,n)).tocsr()\n",
    "\n",
    "  # R = prolongation_fn(n)\n",
    "  # P = R.T\n",
    "  # A=R*A*P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1656897509537,
     "user": {
      "displayName": "Ru Huang",
      "userId": "03213243881794485520"
     },
     "user_tz": 240
    },
    "id": "lNOWxVmFxH4l"
   },
   "outputs": [],
   "source": [
    "def coo_to_tensor(coo):\n",
    "    values = coo.data\n",
    "    indices = np.vstack((coo.row, coo.col))\n",
    "    i = torch.LongTensor(indices)\n",
    "    v = torch.DoubleTensor(values)\n",
    "    shape = coo.shape\n",
    "    temp = coo\n",
    "#     temp =sp.sparse.triu(coo,k=1)\n",
    "#     temp = temp+temp.T\n",
    "#     temp = temp.tocoo()\n",
    "#     row = sp.sparse.triu(coo,k=1).row\n",
    "#     col = sp.sparse.triu(coo,k=1).col\n",
    "#     data = sp.sparse.triu(coo,k=1).data\n",
    "#     for ii in range(len(row)):\n",
    "#         if row[ii]==col[ii]:\n",
    "#             data[ii]=data[ii]/2\n",
    "    row = temp.row\n",
    "    col = temp.col\n",
    "    data = temp.data\n",
    "    return torch.sparse_coo_tensor(i, v, torch.Size(shape),requires_grad = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 4891,
     "status": "ok",
     "timestamp": 1656897514422,
     "user": {
      "displayName": "Ru Huang",
      "userId": "03213243881794485520"
     },
     "user_tz": 240
    },
    "id": "XpTxEtJ56ohc"
   },
   "outputs": [],
   "source": [
    "A_train1 = []\n",
    "A_train2 = []\n",
    "At_train1 = []\n",
    "At_train2 = []\n",
    "s_train = []\n",
    "stencil_train1 = []\n",
    "stencil_train2 = []\n",
    "A_uu_train = []\n",
    "A_uv_train = []\n",
    "test_vec_uu_train = []\n",
    "test_vec_vv_train = []\n",
    "eig_vec_train = []\n",
    "Ag_train = []\n",
    "A0_train = []\n",
    "u_train  = []\n",
    "v_train  = []\n",
    "n = 9\n",
    "eps = 10\n",
    "num_train = 30\n",
    "nu = np.linspace(0.1,0.4,num_train)\n",
    "for iii in range(num_train):\n",
    "    s1,s2 = elasticity(E=1e-5,nu=nu[iii],by=1)\n",
    "    s3 = transpose_stencil_numpy(s2)\n",
    "    s4 = transpose_stencil_numpy(s1)      \n",
    "    Auu = pyamg.gallery.stencil_grid(s1,(n,n))\n",
    "    Auv = pyamg.gallery.stencil_grid(s2,(n,n))\n",
    "    Avu = pyamg.gallery.stencil_grid(s3,(n,n))\n",
    "    Avv = pyamg.gallery.stencil_grid(s4,(n,n))\n",
    "\n",
    "    A_uu_uv = scipy.sparse.hstack((Auu,Auv))\n",
    "    A_vu_vv = scipy.sparse.hstack((Avu,Avv))\n",
    "    A = scipy.sparse.vstack((A_uu_uv,A_vu_vv))\n",
    "\n",
    "\n",
    "    R1_uu_train = pyamg.gallery.stencil_grid(res1_uu,(n,n)).tocsr()\n",
    "    R1_uu = R1_uu_train\n",
    "    P1_uu = R1_uu.T\n",
    "    P1_uu_train = R1_uu_train.T\n",
    "\n",
    "    R1_uv_train = pyamg.gallery.stencil_grid(res1_uv,(n,n)).tocsr()\n",
    "    R1_uv = R1_uv_train\n",
    "    P1_uv = R1_uv.T\n",
    "    P1_uv_train = R1_uv_train.T\n",
    "\n",
    "    R1_vu_train = pyamg.gallery.stencil_grid(res1_vu,(n,n)).tocsr()\n",
    "    R1_vu = R1_vu_train\n",
    "    P1_vu = R1_vu.T\n",
    "    P1_vu_train = R1_vu_train.T\n",
    "\n",
    "    R1_vv_train = pyamg.gallery.stencil_grid(res1_vv,(n,n)).tocsr()\n",
    "    R1_vv = R1_vv_train\n",
    "    P1_vv = R1_vv.T\n",
    "    P1_vv_train = R1_vv_train.T\n",
    "\n",
    "    R_uu_uv = scipy.sparse.hstack((R1_uu,R1_uv))\n",
    "    R_vu_vv = scipy.sparse.hstack((R1_vu,R1_vv))\n",
    "    R = scipy.sparse.vstack((R_uu_uv,R_vu_vv)).tocsr()\n",
    "    R = R[0:n*n*2:2,:]\n",
    "    P = R.T\n",
    "    R_uu_uv_train = scipy.sparse.hstack((R1_uu_train,R1_uv_train))\n",
    "    R_vu_vv_train = scipy.sparse.hstack((R1_vu_train,R1_vv_train))\n",
    "    R_train = scipy.sparse.vstack((R_uu_uv_train,R_vu_vv_train))\n",
    "    P_train = R_train.T\n",
    "    A_train = R_train*A*P_train\n",
    "    T = R_train*P_train\n",
    "\n",
    "    # print(R.shape)\n",
    "    # print(A.shape)\n",
    "    # print(P.shape)\n",
    "    A = R*A*P\n",
    "    # print(A.shape)\n",
    "    # A_test = A_test[0:n*n*2:2,:]\n",
    "    # A_test = A_test[:,0:n*n*2:2]\n",
    "\n",
    "    A_uu = A_train[0:n*n,0:n*n]\n",
    "    A_uv = A_train[0:n*n,n*n:]\n",
    "    A_vu = A_train[n*n:,0:n*n]\n",
    "    A_vv = A_train[n*n:,n*n:]\n",
    "\n",
    "    stencil_uu = compute_stencil(A_uu,n,n,7)\n",
    "    stencil_uv = compute_stencil(A_uv,n,n,5)\n",
    "    stencil_vu = compute_stencil(A_vu,n,n,5)\n",
    "    stencil_vv = compute_stencil(A_vv,n,n,7)\n",
    "\n",
    "    s_uu = stencil_uu[n//2,n//2,:,:]\n",
    "    s_uu[abs(s_uu)<1e-15] = 0\n",
    "    s_uv = stencil_uv[n//2,n//2,:,:]\n",
    "    s_uv[abs(s_uv)<1e-15] = 0\n",
    "    s_vu = stencil_vu[n//2,n//2,:,:]\n",
    "    s_vu[abs(s_vu)<1e-15] = 0\n",
    "    s_vv = stencil_vv[n//2,n//2,:,:]\n",
    "    s_vv[abs(s_vv)<1e-15] = 0\n",
    "    s_uu,_,_ = reorder(s_uu,1)\n",
    "    # A_uu_conv = \n",
    "    # s_uu = s_uu[2:5,1:6]\n",
    "    s_uv,_,_ = reorder(s_uv,2)\n",
    "\n",
    "    s_vu,_,_ = reorder(s_vu,2)\n",
    "\n",
    "    s_vv,_,_ = reorder(s_vv,1)\n",
    "    # s_vv = s_vv[2:5,1:6]\n",
    "\n",
    "    Ag = coo_to_tensor(A.tocoo())\n",
    "    A_uu_conv = nn.Conv2d(1, 1, 3, padding = 0, bias = False).double()\n",
    "    s_uu = s_uu[1:6,1:6]\n",
    "    A_uu_conv.weight = nn.Parameter(s_uu.view(1,1,5,5))\n",
    "    A_vv_conv = nn.Conv2d(1, 1, 3, padding = 0, bias = False).double()\n",
    "    s_vv = s_vv[1:6,1:6]\n",
    "    A_vv_conv.weight = nn.Parameter(s_vv.view(1,1,5,5))\n",
    "\n",
    "    A_uv_conv = nn.Conv2d(1, 1, 4, padding = 0, bias = False).double()\n",
    "    s_uv = s_uv[0:4,0:4]\n",
    "    A_uv_conv.weight = nn.Parameter(s_uv.view(1,1,4,4))\n",
    "    A_vu_conv = nn.Conv2d(1, 1, 4, padding = 0, bias = False).double()\n",
    "    s_vu = s_vu[0:4,0:4]\n",
    "    A_vu_conv.weight = nn.Parameter(s_vu.view(1,1,4,4))\n",
    "    A_uu_train.append(A_uu_conv)\n",
    "    A_uv_train.append(A_uv_conv)\n",
    "\n",
    "    k=10\n",
    "    # eig_value,eig_vec = sp.sparse.linalg.eigs(A,k=k,which = 'SM')\n",
    "\n",
    "    stencil_train = [stencil_uu,stencil_uv,stencil_vu,stencil_vv]\n",
    "    # s_train = [s_uu,s_uv,s_vu,s_vv]\n",
    "    s_train.append([s_uu,s_uv,s_vu])\n",
    "    # eig_vec = eig_vec.T\n",
    "    # eig_value,eig_vec = np.linalg.eig(A.toarray())\n",
    "    eig_value,eig_vec = sp.sparse.linalg.eigs(A_train,M=T,k=k,which = 'SM')\n",
    "    eig_vec = eig_vec.T\n",
    "    eig_vec_uu = eig_vec[:,0:n*n].reshape(k,n,n)\n",
    "    eig_vec_vv = eig_vec[:,n*n:].reshape(k,n,n)\n",
    "    eig_vec_uu = torch.real(torch.from_numpy(eig_vec_uu))\n",
    "    eig_vec_vv = torch.real(torch.from_numpy(eig_vec_vv))\n",
    "    test_vec_uu = reorder(eig_vec_uu,1)[0].view(k,1,n,n)\n",
    "    test_vec_vv = reorder(eig_vec_vv,1)[0].view(k,1,n,n)\n",
    "    test_vec_uu_train.append(test_vec_uu)\n",
    "    test_vec_vv_train.append(test_vec_vv)\n",
    "\n",
    "    # print(test_vec_uu.shape)      \n",
    "\n",
    "    # A_train1.append(A1)\n",
    "    # A_train2.append(A2)\n",
    "    # At_train1.append(A1t)\n",
    "    # At_train2.append(A2t)\n",
    "\n",
    "    # stencil_train1.append(A1.weight)\n",
    "    # stencil_train2.append(A2.weight)\n",
    "\n",
    "    # eig_vec_train.append(eig_vec)\n",
    "    # Ag_train.append(Ag)\n",
    "    # A0_train.append(A0)\n",
    "    # u_train.append(u)\n",
    "    # v_train.append(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1656897514423,
     "user": {
      "displayName": "Ru Huang",
      "userId": "03213243881794485520"
     },
     "user_tz": 240
    },
    "id": "_j6ZXNRPhEXF"
   },
   "outputs": [],
   "source": [
    "def top_k(logits,k,tau=0):\n",
    "    # u,v = torch.topk(x,4)\n",
    "    # y_hard = torch.zeros_like(x).scatter_(-1, v, value)\n",
    "    # y\n",
    "    # gumbels = (\n",
    "    #     -torch.empty_like(logits, memory_format=torch.legacy_contiguous_format).exponential_().log()\n",
    "    # )  # ~Gumbel(0,1)\"\"\n",
    "    # # gumbels = -torch.rand(logits.shape).exponential_().log()\n",
    "    # gumbels = (logits + gumbels) / tau  # ~Gumbel(logits,tau)\n",
    "    # y_soft = gumbels.softmax(-1)\n",
    "    y_soft = logits.softmax(-1)\n",
    "\n",
    "    # Straight through.\n",
    "    # index = y_soft.max(dim, keepdim=True)[1]\n",
    "    index = torch.topk(y_soft,k)[1]\n",
    "    y_hard = torch.zeros_like(logits, memory_format=torch.legacy_contiguous_format).scatter_(-1, index, 1.0)\n",
    "    ret = y_hard - y_soft.detach() + y_soft\n",
    "\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 1324,
     "status": "ok",
     "timestamp": 1656897515742,
     "user": {
      "displayName": "Ru Huang",
      "userId": "03213243881794485520"
     },
     "user_tz": 240
    },
    "id": "iIHfy-MEVZTD"
   },
   "outputs": [],
   "source": [
    "class GNN_prob(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GNN_prob, self).__init__()\n",
    "        self.fc1 = nn.Linear(6,200).double().to(device)\n",
    "        self.fc2 = nn.Linear(200,200).double().to(device)\n",
    "        self.fc3 = nn.Linear(200,200).double().to(device)\n",
    "        self.fc4 = nn.Linear(200,200).double().to(device)\n",
    "        self.fc5 = nn.Linear(200,6).double().to(device)\n",
    "        self.fc6 = nn.Linear(100,14).double().to(device)\n",
    "        self.fc7 = nn.Linear(100,100).double().to(device)\n",
    "\n",
    "        self.fc8 = nn.Linear(100,8).double().to(device)\n",
    "\n",
    "\n",
    "        # torch.nn.init.sparse_(self.fc1.weight,0.1)\n",
    "        # torch.nn.init.sparse_(self.fc2.weight,0.1)\n",
    "        # torch.nn.init.sparse_(self.fc3.weight,0.15)\n",
    "        # torch.nn.init.sparse_(self.fc4.weight,0.15)\n",
    "\n",
    "    def forward(self,X):\n",
    "        X = self.fc1(X)\n",
    "        # X = torch.relu(X)\n",
    "\n",
    "        X = torch.relu(X)\n",
    "        # X = F.leaky_relu(X)  \n",
    "\n",
    "        X = self.fc2(X)\n",
    "        X = torch.relu(X)\n",
    "\n",
    "        # X = torch.relu(X)\n",
    "        # X = F.leaky_relu(X)  \n",
    "        X = self.fc3(X)\n",
    "        X = torch.relu(X)\n",
    "\n",
    "        # X = torch.relu(X)\n",
    "        # X = F.leaky_relu(X)  \n",
    "        X = self.fc4(X)\n",
    "        X = torch.relu(X)\n",
    "        # # X = torch.tanh(X)\n",
    "        X = self.fc5(X)\n",
    "        X = torch.relu(X)\n",
    "\n",
    "        # # X = torch.tanh(X)\n",
    "        # X = self.fc6(X)\n",
    "        # X = torch.tanh(X)\n",
    "\n",
    "        # X = self.fc7(X)\n",
    "        # X = torch.tanh(X)\n",
    "\n",
    "        # # X = F.leaky_relu(X)  \n",
    "        # X = self.fc8(X)\n",
    "        # # X = torch.relu(X)\n",
    "        # X = torch.tanh(X)\n",
    "        # X = torch.tanh(X)\n",
    "\n",
    "        # X = F.leaky_relu(X)  \n",
    "      \n",
    "        return X\n",
    "class GNN_value(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GNN_value, self).__init__()\n",
    "        self.fc1 = nn.Linear(6,280).double().to(device)\n",
    "        self.fc2 = nn.Linear(280,280).double().to(device)\n",
    "        self.fc3 = nn.Linear(280,200).double().to(device)\n",
    "        self.fc4 = nn.Linear(200,200).double().to(device)\n",
    "        self.fc5 = nn.Linear(200,6).double().to(device)\n",
    "\n",
    "        self.fc6 = nn.Linear(100,14).double().to(device)\n",
    "        torch.nn.init.eye_(self.fc1.weight)\n",
    "        torch.nn.init.eye_(self.fc2.weight)\n",
    "        torch.nn.init.eye_(self.fc3.weight)\n",
    "        torch.nn.init.eye_(self.fc4.weight)\n",
    "        torch.nn.init.eye_(self.fc5.weight)\n",
    "    def forward(self,X):\n",
    "        X = self.fc1(X)\n",
    "        # X = torch.relu(X)\n",
    "        X = F.leaky_relu(X)  \n",
    "\n",
    "        X = self.fc2(X)\n",
    "        # X = torch.relu(X)\n",
    "        X = F.leaky_relu(X)  \n",
    "        X = self.fc3(X)\n",
    "        X = F.leaky_relu(X)  \n",
    "        X = self.fc4(X)\n",
    "        X = F.leaky_relu(X)  \n",
    "        X = self.fc5(X)\n",
    "        X = F.leaky_relu(X)  \n",
    "\n",
    "        # X = torch.tanh(X)\n",
    "        # X = self.fc5(X)\n",
    "\n",
    "        # # X = torch.relu(X)\n",
    "        # X = torch.tanh(X)\n",
    "        # X = self.fc6(X)\n",
    "        # X = F.leaky_relu(X)  \n",
    "        # X = torch.tanh(X)\n",
    "        # X = F.leaky_relu(X)  \n",
    "      \n",
    "        return X\n",
    "\n",
    "def sparsify(prob,value,K,stencil_train):\n",
    "    # prob = torch.sigmoid(X[0:8])\n",
    "    # prob = X[0:8]\n",
    "    prob = top_k(prob,K).squeeze()\n",
    "    stencil = prob*value\n",
    "    # stencil = value\n",
    "    stencil = stencil.view(-1,1)\n",
    "    stencil_uu = torch.from_numpy(stencil_train[0]).clone()\n",
    "    stencil_uv = torch.from_numpy(stencil_train[1]).clone()\n",
    "    stencil_vu = torch.from_numpy(stencil_train[2]).clone()\n",
    "    stencil_vv = torch.from_numpy(stencil_train[3]).clone()\n",
    "    m,n,_,_ = stencil_uu.shape\n",
    "    s_uu = torch.zeros(5,5).double()\n",
    "    ss_uu = torch.zeros(7,7).double()\n",
    "    s_uv = torch.zeros(4,4).double()\n",
    "    ss_uv = torch.zeros(5,5).double()\n",
    "\n",
    "    s_vu = torch.zeros(4,4).double()\n",
    "    ss_vu = torch.zeros(5,5).double()\n",
    "\n",
    "    s_vv = torch.zeros(5,5).double()\n",
    "    ss_vv = torch.zeros(7,7).double()\n",
    "\n",
    "    s_uu[0,0] = 0\n",
    "    s_uu[0,1] = stencil[0]\n",
    "    s_uu[0,2] = 0\n",
    "    s_uu[0,3] = stencil[1]\n",
    "    s_uu[0,4] = 0\n",
    "    s_uu[1,0] = stencil[1]\n",
    "    s_uu[1,1] = stencil[2]\n",
    "    s_uu[1,2] = stencil[3]\n",
    "    s_uu[1,3] = stencil[4]\n",
    "    s_uu[1,4] = stencil[0]\n",
    "    s_uu[2,0] = 0\n",
    "    s_uu[2,1] = stencil[3]\n",
    "    s_uu[2,2] = -stencil[0]*4-stencil[1]*4-stencil[2]*2-4*stencil[3]-2*stencil[4]\n",
    "    s_uu[2,3] = stencil[3]\n",
    "    s_uu[2,4] = 0\n",
    "    s_uu[3,0] = stencil[0]\n",
    "    s_uu[3,1] = stencil[4]\n",
    "    s_uu[3,2] = stencil[3]\n",
    "    s_uu[3,3] = stencil[2]\n",
    "    s_uu[3,4] = stencil[1]\n",
    "    s_uu[4,0] = 0\n",
    "    s_uu[4,1] = stencil[1]\n",
    "    s_uu[4,2] = 0\n",
    "    s_uu[4,3] = stencil[0]\n",
    "    s_uu[4,4] = 0\n",
    "    ss_uu[1:6,1:6] = s_uu\n",
    "\n",
    "    s_vv[0,0] = 0\n",
    "    s_vv[0,1] = stencil[1]\n",
    "    s_vv[0,2] = 0\n",
    "    s_vv[0,3] = stencil[0]\n",
    "    s_vv[0,4] = 0\n",
    "    s_vv[1,0] = stencil[0]\n",
    "    s_vv[1,1] = stencil[2]\n",
    "    s_vv[1,2] = stencil[3]\n",
    "    s_vv[1,3] = stencil[4]\n",
    "    s_vv[1,4] = stencil[1]\n",
    "    s_vv[2,0] = 0\n",
    "    s_vv[2,1] = stencil[3]\n",
    "    s_vv[2,2] = -stencil[0]*4-stencil[1]*4-stencil[2]*2-4*stencil[3]-2*stencil[4]\n",
    "    s_vv[2,3] = stencil[3]\n",
    "    s_vv[2,4] = 0\n",
    "    s_vv[3,0] = stencil[1]\n",
    "    s_vv[3,1] = stencil[4]\n",
    "    s_vv[3,2] = stencil[3]\n",
    "    s_vv[3,3] = stencil[2]\n",
    "    s_vv[3,4] = stencil[0]\n",
    "    s_vv[4,0] = 0\n",
    "    s_vv[4,1] = stencil[0]\n",
    "    s_vv[4,2] = 0\n",
    "    s_vv[4,3] = stencil[1]\n",
    "    s_vv[4,4] = 0\n",
    "    \n",
    "    ss_vv[1:6,1:6] = s_vv\n",
    "\n",
    "    s_uv[0,0] = 0\n",
    "    s_uv[0,1] = stencil[5]\n",
    "    s_uv[0,2] = stencil[5]\n",
    "    s_uv[0,3] = 0\n",
    "    s_uv[1,0] = -stencil[5]\n",
    "    # s_uv[1,1] = stencil[6]\n",
    "    # s_uv[1,2] = stencil[7]\n",
    "    s_uv[1,3] = -stencil[5]\n",
    "    s_uv[2,0] = -stencil[5]\n",
    "    # s_uv[2,1] = stencil[8]\n",
    "    # s_uv[2,2] = stencil[9]\n",
    "    s_uv[2,3] = -stencil[5]\n",
    "    s_uv[3,0] = 0\n",
    "    s_uv[3,1] = stencil[5]\n",
    "    s_uv[3,2] = stencil[5]\n",
    "    s_uv[3,3] = 0\n",
    "    ss_uv[0:4,0:4] = s_uv\n",
    "\n",
    "    s_vu[0,0] = 0\n",
    "    s_vu[0,1] = stencil[5]\n",
    "    s_vu[0,2] = stencil[5]\n",
    "    s_vu[0,3] = 0\n",
    "    s_vu[1,0] = -stencil[5]\n",
    "    # s_vu[1,1] = stencil[10]\n",
    "    # s_vu[1,2] = stencil[11]\n",
    "    s_vu[1,3] = -stencil[5]\n",
    "    s_vu[2,0] = -stencil[5]\n",
    "    # s_vu[2,1] = stencil[12]\n",
    "    # s_vu[2,2] = stencil[13]\n",
    "    s_vu[2,3] = -stencil[5]\n",
    "    s_vu[3,0] = 0\n",
    "    s_vu[3,1] = stencil[5]\n",
    "    s_vu[3,2] = stencil[5]\n",
    "    s_vu[3,3] = 0\n",
    "    ss_vu[0:4,0:4] = s_vu\n",
    "\n",
    "\n",
    "\n",
    "    ss_uu,_,_ = reorder_T(ss_uu.detach(),1)\n",
    "    ss_uv,_,_ = reorder_T(ss_uv.detach(),2)\n",
    "    ss_vu,_,_ = reorder_T(ss_vu.detach(),2)\n",
    "    ss_vv,_,_ = reorder_T(ss_vv.detach(),1)\n",
    "\n",
    "    for i in range(2,m-2):\n",
    "        for j in range(2,n-2):\n",
    "            stencil_uu[i,j,:,:] = ss_uu\n",
    "            stencil_uv[i,j,:,:] = ss_uv\n",
    "            stencil_vu[i,j,:,:] = ss_vu\n",
    "            stencil_vv[i,j,:,:] = ss_vv\n",
    "    # u,v = torch.topk(torch.sigmoid(prob),4) \n",
    "    return stencil_uu,stencil_uv,stencil_vu,stencil_vv,s_uu,s_uv,s_vu,s_vv,ss_uu,ss_uv,ss_vu,ss_vv\n",
    "\n",
    "\n",
    "def train(A_uu_train,A_uv_train,test_vec_uu_train,test_vec_vv_train,s_train,epochs,learning_rate,model_prob,model_value):\n",
    "\n",
    "#     model = GCN(32,32,10)\n",
    "    optimizer = torch.optim.Adam(list(model_prob.parameters())+list(model_value.parameters()),lr=learning_rate)\n",
    "    # optimizer = torch.optim.SGD(list(model_prob.parameters())+list(model_value.parameters()), lr=learning_rate)\n",
    "\n",
    "    tau = 1\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        loss = 0\n",
    "        optimizer.zero_grad()\n",
    "     \n",
    "        for j in range(len(A_uv_train)):\n",
    "            # for j in range(len(A_train1)):\n",
    "            # s_uu,s_uv,s_vu,s_vv = s_train\n",
    "            s_uu,s_uv,s_vu = s_train[j]\n",
    "            A_uu_conv = A_uu_train[j]\n",
    "            A_uv_conv = A_uv_train[j]  \n",
    "            test_vec_uu = test_vec_uu_train[j]\n",
    "            test_vec_vv = test_vec_vv_train[j]\n",
    "            n = 17\n",
    "\n",
    "            # s_uv = torch.from_numpy(s_uv).view(-1,1).clone()\n",
    "            # s_vu = torch.from_numpy(s_vu).view(-1,1).clone()\n",
    "            # s_vv = torch.from_numpy(s_vv).view(-1,1).clone()\n",
    "            # stencil_uu_train = torch.cat([s_uu[0:24],s_uu[25:49]])\n",
    "            # stencil_uv_train = torch.cat([s_uv[0:24],s_uv[25:49]])\n",
    "            # stencil_vu_train = torch.cat([s_vu[0:24],s_vu[25:49]])\n",
    "            # stencil_vv_train = torch.cat([s_vv[0:24],s_vv[25:49]])\n",
    "            # stencil = torch.cat([stencil_uu_train,stencil_uv_train,stencil_vu_train,stencil_vv_train]).view(1,-1)\n",
    "            stencil = torch.zeros(1,6).double()\n",
    "            stencil[0,0] = s_uu[0,1]\n",
    "            stencil[0,1] = s_uu[0,3]\n",
    "            stencil[0,2] = s_uu[1,1]\n",
    "            stencil[0,3] = s_uu[1,2]\n",
    "            stencil[0,4] = s_uu[1,3]\n",
    "            stencil[0,5] = s_uv[0,1]\n",
    "            # stencil[0,6] = s_uv[1,1]\n",
    "            # stencil[0,7] = s_uv[1,2]\n",
    "            # stencil[0,8] = s_uv[2,1]\n",
    "            # stencil[0,9] = s_uv[2,2]\n",
    "            # stencil[0,10] = s_vu[1,1]\n",
    "            # stencil[0,11] = s_vu[1,2]\n",
    "            # stencil[0,12] = s_vu[2,1]\n",
    "            # stencil[0,13] = s_vu[2,2]\n",
    "\n",
    "            # stencil[0,7] = s_uu[3,3]\n",
    "            # stencil[0,8] = s_uu[3,4]\n",
    "            # stencil[0,9] = s_uu[3,5]\n",
    "            # stencil[0,10] = s_uu[4,1]\n",
    "            # stencil[0,11] = s_uu[4,2]\n",
    "            # stencil[0,12] = s_uu[4,3]\n",
    "            # stencil[0,13] = s_uu[4,4]\n",
    "            # stencil[0,14] = s_uu[4,5]\n",
    "\n",
    "            prob = model_prob(stencil).squeeze()\n",
    "            # print(stencil)\n",
    "            value = model_value(stencil).squeeze()\n",
    "            # print(value)\n",
    "            # print(stencil)\n",
    "            # value = stencil\n",
    "            stencil_uu,stencil_uv,stencil_vu,stencil_vv,s_uu,s_uv,s_vu,s_vv,ss_uu,ss_uv,ss_vu,ss_vv = sparsify(prob,value,int(len(prob)*0.5),stencil_train)\n",
    "            temp_uu = F.conv2d(test_vec_uu,s_uu.view(1,1,5,5),padding=0)-A_uu_conv(test_vec_uu)\n",
    "            temp_uv = F.conv2d(test_vec_vv,s_uv.view(1,1,4,4),padding=0)-A_uv_conv(test_vec_vv)\n",
    "\n",
    "            # temp = ss_uu-A_uu_conv.weight.squeeze()\n",
    "            loss += torch.norm(temp_uu)**2+torch.norm(temp_uv)**2\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # temp = torch.mm(A_c,eig_vec)-torch.mm(Ag.to_dense(),eig_vec)\n",
    "        # # print(temp)\n",
    "        # # temp = temp.squeeze(1).view(temp.shape[0],-1,1)\n",
    "        # loss+=torch.norm(temp)**2\n",
    "        # loss.backward()\n",
    "\n",
    "        # for name, param in model_value.named_parameters():\n",
    "        #     print(name, param.grad)\n",
    "\n",
    "        if epoch%1000==0:\n",
    "            print(' epoch: ',epoch,' loss: ',loss)\n",
    "    A_uu = compute_A(stencil_uu,stencil_uu.shape[0],stencil_uu.shape[1],stencil_uu.shape[2]).to_dense()\n",
    "    A_uv = compute_A(stencil_uv,stencil_uv.shape[0],stencil_uv.shape[1],stencil_uv.shape[2]).to_dense()\n",
    "    A_vu = compute_A(stencil_vu,stencil_vu.shape[0],stencil_vu.shape[1],stencil_vu.shape[2]).to_dense()\n",
    "    A_vv = compute_A(stencil_vv,stencil_vv.shape[0],stencil_vv.shape[1],stencil_vv.shape[2]).to_dense()\n",
    "    A_uu_uv = torch.hstack((A_uu,A_uv))\n",
    "    A_vu_vv = torch.hstack((A_vu,A_vv))\n",
    "    A_c = torch.vstack((A_uu_uv,A_vu_vv))\n",
    "    A_c = A_c[0:n*n*2:2,:]\n",
    "    A_c = A_c[:,0:n*n*2:2]\n",
    "\n",
    "    return model_prob,model_value,A_c,ss_uu,ss_vv,ss_uv,ss_vu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3161,
     "status": "ok",
     "timestamp": 1656897547352,
     "user": {
      "displayName": "Ru Huang",
      "userId": "03213243881794485520"
     },
     "user_tz": 240
    },
    "id": "Ue9M-GPRVbiS",
    "outputId": "5f0288de-aff2-4f42-fbc0-b89d2c62d84b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " epoch:  0  loss:  tensor(3.5735, dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# n = 31\n",
    "# num_eigenvecs = n*n\n",
    "# eig_vec = torch.rand(num_eigenvecs,1,n,n).double()\n",
    "# b = torch.rand(num_eigenvecs,1,n,n).doubl()\n",
    "# for k in range(10):\n",
    "#   # eig_vec = np.matmul(np.linalg.inv(L.toarray()),b-np.matmul(U.toarray(),eig_vec))\n",
    "#   eig_vec = 2/(3*A0.weight[0,0,1,1])*(b-A0(eig_vec))+eig_vec\n",
    "# eig_vec = b-A0(eig_vec)\n",
    "# eig_vec = res(eig_vec)\n",
    "model_prob = GNN_prob()\n",
    "model_value = GNN_value()\n",
    "mxl = 1\n",
    "for i in range(mxl):\n",
    "    model_prob,model_value,A_c,ss_uu,ss_vv,ss_uv,ss_vu = train(A_uu_train,A_uv_train,test_vec_uu_train,test_vec_vv_train,s_train,80,1e-5,model_prob,model_value)\n",
    "    # print(coarse_stencil)\n",
    "    # A = pyamg.gallery.stencil_grid(coarse_stencil.squeeze().detach().numpy(),(n,n)).tocsr()\n",
    "    # A0 = coo_to_tensor(A.tocoo())\n",
    "    # k=10\n",
    "\n",
    "    # R = prolongation_fn(n)\n",
    "    # P = R.T\n",
    "    # T = R*P\n",
    "\n",
    "    # A=R*A*P\n",
    "\n",
    "    # Ag = coo_to_tensor(A.tocoo())\n",
    "    # eig_value,eig_vec = sp.sparse.linalg.eigs(A,k=k,M=T,which = 'SM')\n",
    "    # eig_vec = eig_vec.T\n",
    "    # eig_vec = torch.real(torch.from_numpy(eig_vec)).view(k,1,n//2,n//2)\n",
    "    # A = project_stencil(coarse_stencil.view(1,1,3,3))\n",
    "    # A_train.append(A)\n",
    "    # stencil_train.append(A.weight)\n",
    "    # eig_vec_train.append(eig_vec)\n",
    "    # Ag_train.append(Ag)\n",
    "    # A0_train.append(A0)\n",
    "    # print('level '+str(i)+' training done! ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 535,
     "status": "ok",
     "timestamp": 1656897550251,
     "user": {
      "displayName": "Ru Huang",
      "userId": "03213243881794485520"
     },
     "user_tz": 240
    },
    "id": "Op4LDH5cjeZm"
   },
   "outputs": [],
   "source": [
    "def geometric_solver(A,option1,option2,models,n,\n",
    "                     presmoother=('gauss_seidel', {'sweep': 'forward'}),\n",
    "                     postsmoother=('gauss_seidel', {'sweep': 'forward'}),\n",
    "                     max_levels=5, max_coarse=10,coarse_solver='splu',stencil=0,**kwargs):\n",
    "   \n",
    "    levels = [multilevel_solver.level()]\n",
    "\n",
    "    # convert A to csr\n",
    "    if not isspmatrix_csr(A):\n",
    "        try:\n",
    "            A = csr_matrix(A)\n",
    "            warn(\"Implicit conversion of A to CSR\",\n",
    "                 SparseEfficiencyWarning)\n",
    "        except BaseException:\n",
    "            raise TypeError('Argument A must have type csr_matrix, \\\n",
    "                             or be convertible to csr_matrix')\n",
    "    # preprocess A\n",
    "    A = A.asfptype()\n",
    "    if A.shape[0] != A.shape[1]:\n",
    "        raise ValueError('expected square matrix')\n",
    "\n",
    "    levels[-1].A = A\n",
    "    levels[-1].stencil = stencil\n",
    "    levels[-1].n = n\n",
    "\n",
    "    while len(levels) < max_levels and levels[-1].A.shape[0] > max_coarse:\n",
    "        extend_hierarchy(levels,option1,option2,models,stencil)\n",
    "\n",
    "    ml = multilevel_solver(levels, **kwargs)\n",
    "    change_smoothers(ml, presmoother, postsmoother)\n",
    "    return ml\n",
    "\n",
    "# internal function\n",
    "def extend_hierarchy(levels,option1,option2,models,stencil):\n",
    "    \"\"\"Extend the multigrid hierarchy.\"\"\"\n",
    "    if len(levels) == 1:   \n",
    "        A = levels[-1].A\n",
    "        n = levels[-1].n\n",
    "        model = models[len(levels)-1]\n",
    "        R1_uu_train = pyamg.gallery.stencil_grid(res1_uu,(n,n)).tocsr()\n",
    "        # R1_uu_train[idx,:] = 0\n",
    "        R1_uu = R1_uu_train\n",
    "        I = scipy.sparse.csr_matrix(R1_uu.shape)\n",
    "        P1_uu = R1_uu.T\n",
    "        R1_uv_train = pyamg.gallery.stencil_grid(res1_uv,(n,n)).tocsr()\n",
    "        # R1_uv_train[idx,:] = 0\n",
    "\n",
    "        R1_uv = R1_uv_train\n",
    "        P1_uv = R1_uv.T\n",
    "        R1_vu_train = pyamg.gallery.stencil_grid(res1_vu,(n,n)).tocsr()\n",
    "        # R1_vu_train[idx,:] = 0\n",
    "\n",
    "        R1_vu = R1_vu_train\n",
    "        P1_vu = R1_vu.T\n",
    "        R1_vv_train = pyamg.gallery.stencil_grid(res1_vv,(n,n)).tocsr()\n",
    "        # R1_vv_train[idx,:] = 0\n",
    "\n",
    "        R1_vv = R1_vv_train\n",
    "        P1_vv = R1_vv.T\n",
    "        # print(R1_uv.T.toarray())\n",
    "        R_uu_uv = scipy.sparse.hstack((R1_uu,R1_vu))\n",
    "        R_vu_vv = scipy.sparse.hstack((R1_uv,R1_vv))\n",
    "        # R_uu_uv = scipy.sparse.hstack((R1_uu,I))\n",
    "        # R_vu_vv = scipy.sparse.hstack((I,R1_vv))\n",
    "\n",
    "        R_train = scipy.sparse.vstack((R_uu_uv,R_vu_vv)).tocsr()\n",
    "        R = R_train[0:n*n*2:2,:]\n",
    "        P = R.T\n",
    "\n",
    "        if option1=='standard':\n",
    "            # Form next level through Galerkin product        # print(A)\n",
    "            print(R.shape)\n",
    "            print(A.shape)\n",
    "            A = R*A*P\n",
    "            # eig_value,eig_vec = sp.sparse.linalg.eigs(A,feature_dims,which = 'SM')\n",
    "            # X = torch.real(torch.from_numpy(eig_vec).to(device))\n",
    "            n=n//2\n",
    "            levels[-1].P = P  # prolongation operator\n",
    "            levels[-1].R = R  # restriction operator\n",
    "\n",
    "            levels.append(multilevel_solver.level())\n",
    "            A = A.astype(np.float64)  # convert from complex numbers, should have A.imag==0\n",
    "            levels[-1].A = A.tocsr()\n",
    "            levels[-1].n = n\n",
    "        else:\n",
    "            if len(levels) == 1:\n",
    "                A_train = R_train*A*R_train.T\n",
    "                A_uu = A_train[0:n*n,0:n*n]\n",
    "                A_uv = A_train[0:n*n,n*n:]\n",
    "                A_vu = A_train[n*n:,0:n*n]\n",
    "                A_vv = A_train[n*n:,n*n:]\n",
    "\n",
    "                stencil_uu = compute_stencil(A_uu,n,n,7)\n",
    "                stencil_uv = compute_stencil(A_uv,n,n,5)\n",
    "                stencil_vu = compute_stencil(A_vu,n,n,5)\n",
    "                stencil_vv = compute_stencil(A_vv,n,n,7)\n",
    "                stencil_test = [stencil_uu,stencil_uv,stencil_vu,stencil_vv]\n",
    "\n",
    "                s_uu = torch.from_numpy(stencil_uu[n//2,n//2,:,:])\n",
    "                s_uv = torch.from_numpy(stencil_uv[n//2,n//2,:,:])\n",
    "                stencil = torch.zeros(1,6).double()\n",
    "                stencil[0,0] = s_uu[0,1]\n",
    "                stencil[0,1] = s_uu[0,3]\n",
    "                stencil[0,2] = s_uu[1,1]\n",
    "                stencil[0,3] = s_uu[1,2]\n",
    "                stencil[0,4] = s_uu[1,3]\n",
    "                stencil[0,5] = s_uv[0,1]\n",
    "\n",
    "                prob = model_prob(stencil).squeeze()\n",
    "                value = model_value(stencil).squeeze()\n",
    "                stencil_uu,stencil_uv,stencil_vu,stencil_vv,s_uu,s_uv,s_vu,s_vv,ss_uu,ss_uv,ss_vu,ss_vv = sparsify(prob,value,int(len(prob)*0.5),stencil_test)\n",
    "\n",
    "                A_uu = compute_A_numpy(stencil_uu,stencil_uu.shape[0],stencil_uu.shape[1],stencil_uu.shape[2])\n",
    "                A_uv = compute_A_numpy(stencil_uv,stencil_uv.shape[0],stencil_uv.shape[1],stencil_uv.shape[2])\n",
    "                A_vu = compute_A_numpy(stencil_vu,stencil_vu.shape[0],stencil_vu.shape[1],stencil_vu.shape[2])\n",
    "                A_vv = compute_A_numpy(stencil_vv,stencil_uu.shape[0],stencil_uu.shape[1],stencil_uu.shape[2])\n",
    "                A_uu_uv = scipy.sparse.hstack((A_uu,A_uv))\n",
    "                A_vu_vv = scipy.sparse.hstack((A_vu,A_vv))\n",
    "                A_c = scipy.sparse.vstack((A_uu_uv,A_vu_vv)).tocsr()\n",
    "                A_c = A_c[0:n*n*2:2,:]\n",
    "                A_c = A_c[:,0:n*n*2:2]\n",
    "\n",
    "                levels[-1].P = P  # prolongation operator\n",
    "                levels[-1].R = R  # restriction operator\n",
    "                n=n//2\n",
    "                levels.append(multilevel_solver.level())\n",
    "                # stencil = project_stencil(stencil).weight\n",
    "\n",
    "                # s = np.array([[0,-1,0],[-1,4,-1],[0,-1,0]])/16**(len(levels)-1) \n",
    "                levels[-1].A = A_c\n",
    "        #         print(A_c.shape)\n",
    "                print('naive',A_c.count_nonzero()/(R*A*P).count_nonzero())\n",
    "                # print(' theta ',np.linalg.norm(np.identity(A_c.shape[0])-np.matmul(np.linalg.inv(A_c.toarray()),(R*A*P).toarray()),2))\n",
    "            else:\n",
    "                A = R*A*P\n",
    "                # eig_value,eig_vec = sp.sparse.linalg.eigs(A,feature_dims,which = 'SM')\n",
    "                # X = torch.real(torch.from_numpy(eig_vec).to(device))\n",
    "                n=n//2\n",
    "                levels[-1].P = P  # prolongation operator\n",
    "                levels[-1].R = R  # restriction operator\n",
    "\n",
    "                levels.append(multilevel_solver.level())\n",
    "                A = A.astype(np.float64)  # convert from complex numbers, should have A.imag==0\n",
    "                levels[-1].A = A.tocsr()\n",
    "\n",
    "        levels[-1].n=n\n",
    "    else:\n",
    "        A = levels[-1].A\n",
    "        C = pyamg.strength.classical_strength_of_connection(A.tocsr())\n",
    "        # C = algebraic_distance(A.tocsr())\n",
    "        def unpack_arg(v):\n",
    "            if isinstance(v, tuple):\n",
    "                return v[0], v[1]\n",
    "            else:\n",
    "                return v, {}\n",
    "        flag, kwargs = unpack_arg(False)\n",
    "        AggOp = standard_aggregation(C, **kwargs)[0]\n",
    "        # AggOp = naive_aggregation(C, **kwargs)[0]\n",
    "\n",
    "        #AggOp =   lloyd_aggregation(C, **kwargs)[0]\n",
    "\n",
    "        B = np.kron(np.ones((int(A.shape[0]/pyamg.util.utils.get_blocksize(A)), 1), dtype=A.dtype),\n",
    "                  np.eye(pyamg.util.utils.get_blocksize(A), dtype=A.dtype))\n",
    "        T, B = fit_candidates(AggOp, B)\n",
    "        # #P = jacobi_prolongation_smoother(A, T, C, B, **kwargs)\n",
    "        # P = richardson_prolongation_smoother(A,T,**kwargs)\n",
    "        # T = prolongation_fn(int(np.sqrt(A.shape[0]))).T\n",
    "        P = jacobi_prolongation_smoother(A, T, C, np.ones(T.shape[1]))\n",
    "        R = P.T\n",
    "        levels[-1].P = P  # prolongation operator\n",
    "        levels[-1].R = R  # restriction operator\n",
    "        levels.append(multilevel_solver.level())\n",
    "        # stencil = project_stencil(stencil).weight\n",
    "\n",
    "        # s = np.array([[0,-1,0],[-1,4,-1],[0,-1,0]])/16**(len(levels)-1) \n",
    "        levels[-1].A = R*A*P\n",
    "    print(str(len(levels)),levels[-1].A.tocsr()[levels[-1].A.tocsr().shape[0]//2,:].count_nonzero())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1656897550253,
     "user": {
      "displayName": "Ru Huang",
      "userId": "03213243881794485520"
     },
     "user_tz": 240
    },
    "id": "GdkbIs9_pX29"
   },
   "outputs": [],
   "source": [
    "def fx(x,y,nu):\n",
    "    A1 = (-66+82*nu)*np.cos(np.pi*(5*x+4*y))\n",
    "    A2 = -21*np.cos(np.pi*3*x)*np.sin(7*np.pi*y)\n",
    "    return np.pi*np.pi*(A1+A2)/(2*(-1+nu+2*nu*nu))\n",
    "def fy(x,y,nu):\n",
    "    A1 = -20*np.cos(np.pi*(5*x+4*y))\n",
    "    A2 = (-107+116*nu)*np.cos(np.pi*7*y)*np.sin(3*np.pi*x)\n",
    "    return np.pi*np.pi*(A1+A2)/(2*(-1+nu+2*nu*nu))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3446,
     "status": "ok",
     "timestamp": 1656897554356,
     "user": {
      "displayName": "Ru Huang",
      "userId": "03213243881794485520"
     },
     "user_tz": 240
    },
    "id": "w4ga9khgjeZn",
    "outputId": "525a1501-d6b6-4820-e56d-20dff7b7d89c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: level() is deprectated.  use Level()\n",
      "  \n",
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:80: DeprecationWarning: level() is deprectated.  use Level()\n",
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:28: DeprecationWarning: multilevel_solver is deprectated.  use MultilevelSolver()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1089, 2178)\n",
      "(2178, 2178)\n",
      "2 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:125: DeprecationWarning: level() is deprectated.  use Level()\n",
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:28: DeprecationWarning: multilevel_solver is deprectated.  use MultilevelSolver()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naive 0.49494265973359924\n",
      "2 10\n",
      "standard iter:    10.0   standard time:     0.7773849964141846\n",
      "non galerkin iter:    1001.0   non galerkin time:     1.4753844738006592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/pyamg/multilevel.py:595: RuntimeWarning: overflow encountered in add\n",
      "  x += self.levels[lvl].P * coarse_x   # coarse grid correction\n"
     ]
    }
   ],
   "source": [
    "# torch.set_printoptions(precision=10)\n",
    "num_test = 1\n",
    "t1=time.time()\n",
    "num_iter = []\n",
    "num_iter2 = []\n",
    "num_iter3 = []\n",
    "num_iter4 = []\n",
    "t_iter = []\n",
    "t_iter2 = []\n",
    "t_iter3 = []\n",
    "t_iter4 = []\n",
    "res_s = []\n",
    "res2_s = []\n",
    "res3_s = []\n",
    "res4_s = []\n",
    "test_grid_size = 129\n",
    "model1=0\n",
    "model2=0\n",
    "model3=0\n",
    "\n",
    "for i in range(num_test):\n",
    "    nu = np.random.rand()*0.09+0.211\n",
    "    s1,s2 = elasticity(E=1e-5,nu=nu,by=1)\n",
    "    s3 = transpose_stencil_numpy(s2)\n",
    "    s4 = transpose_stencil_numpy(s1)      \n",
    "    x = np.linspace(0, 1, test_grid_size)\n",
    "    y = np.linspace(0, 1, test_grid_size)\n",
    "    xv, yv = np.meshgrid(x, y)\n",
    "    uu = fx(xv,yv,0.3).reshape(-1,1)\n",
    "    vv = fy(xv,yv,0.3).reshape(-1,1)\n",
    "    b = np.vstack((uu,vv))\n",
    "    Auu = pyamg.gallery.stencil_grid(s1,(test_grid_size,test_grid_size)).tocsr()\n",
    "    Auv = pyamg.gallery.stencil_grid(s2,(test_grid_size,test_grid_size)).tocsr()\n",
    "    Avu = pyamg.gallery.stencil_grid(s3,(test_grid_size,test_grid_size)).tocsr()\n",
    "    Avv = pyamg.gallery.stencil_grid(s4,(test_grid_size,test_grid_size)).tocsr()\n",
    "\n",
    "    A_uu_uv = scipy.sparse.hstack((Auu,Auv))\n",
    "    A_vu_vv = scipy.sparse.hstack((Avu,Avv))\n",
    "    A_orig = scipy.sparse.vstack((A_uu_uv,A_vu_vv)).tocsr()\n",
    "\n",
    "\n",
    "    solver_standard = geometric_solver(A_orig,'standard',0,[model1,model2,model3],test_grid_size,max_levels=2,coarse_solver='splu')\n",
    "    solver_non_galerkin = geometric_solver(A_orig,'non-galerkin','GNN',[model1,model2,model3],test_grid_size,max_levels=2,coarse_solver='splu', stencil =0)\n",
    "    # solver_non_galerkin_NONGNN = geometric_solver(A_orig,'234','123',[model1,model2,model3],test_grid_size,max_levels=2,coarse_solver='splu',stencil = torch.from_numpy(s).reshape(1,1,3,3))\n",
    "\n",
    "    x0 = np.ones((A_orig.shape[0],1))\n",
    "    # b = np.zeros((A_orig.shape[0],1))\n",
    "\n",
    "    res=[]\n",
    "    res2= []\n",
    "    res3= []\n",
    "    res4 = []\n",
    "    t1 =time.time()\n",
    "    x1 = solver_standard.solve(b,x0=x0,maxiter=1000, tol=1e-6,residuals=res)\n",
    "    t2=time.time()\n",
    "    x2 = solver_non_galerkin.solve(b,x0=x0,maxiter=1000, tol=1e-6,residuals=res2)\n",
    "    t3=time.time()\n",
    "    # x = solver_non_galerkin_NONGNN.solve(b,x0=x0,maxiter=1000, tol=1e-6,residuals=res3)\n",
    "    # t4=time.time()\n",
    "    # x = solver_naive.solve(b,x0=x0,maxiter=1000, tol=1e-6,residuals=res4)\n",
    "    # t5=time.time()\n",
    "\n",
    "    res_s.append(res)\n",
    "    res2_s.append(res2)\n",
    "    # res3_s.append(res3)\n",
    "    # res4_s.append(res4)\n",
    "\n",
    "    num_iter.append(len(res))\n",
    "    num_iter2.append(len(res2))\n",
    "    # num_iter3.append(len(res3))\n",
    "    # num_iter4.append(len(res4))\n",
    "\n",
    "    t_iter.append(t2-t1)\n",
    "    t_iter2.append(t3-t2)\n",
    "    # t_iter3.append(t4-t3)\n",
    "    # t_iter4.append(t5-t4)\n",
    "\n",
    "\n",
    "print('standard iter:   ',np.mean(num_iter),'  standard time:    ',np.mean(t_iter))\n",
    "print('non galerkin iter:   ',np.mean(num_iter2),'  non galerkin time:    ',np.mean(t_iter2))\n",
    "# print('non galerkin nongnn iter:   ',np.mean(num_iter3),'  non galerkin time:    ',np.mean(t_iter3))\n",
    "# print('naive iter:   ',np.mean(num_iter4),'  non galerkin time:    ',np.mean(t_iter4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 1216,
     "status": "ok",
     "timestamp": 1656897555567,
     "user": {
      "displayName": "Ru Huang",
      "userId": "03213243881794485520"
     },
     "user_tz": 240
    },
    "id": "42g_ec3ISpwd"
   },
   "outputs": [],
   "source": [
    "Ag = solver_standard.levels[-1].A\n",
    "Ac = solver_non_galerkin.levels[-1].A\n",
    "\n",
    "# Ag_eig = scipy.linalg.eigvals(Ag.toarray())\n",
    "# Ac_eig = scipy.linalg.eigvals(Ac.toarray())\n",
    "test_vec = np.matmul(Ac.toarray(),sp.linalg.inv(Ag.toarray()))\n",
    "eig1 = scipy.linalg.eigvals(test_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "aborted",
     "timestamp": 1656897540523,
     "user": {
      "displayName": "Ru Huang",
      "userId": "03213243881794485520"
     },
     "user_tz": 240
    },
    "id": "XA4-DYs1276X"
   },
   "outputs": [],
   "source": [
    "Ag = solver_standard.levels[-1].A\n",
    "Ac = solver_non_galerkin.levels[-1].A\n",
    "\n",
    "# Ag_eig = scipy.linalg.eigvals(Ag.toarray())\n",
    "# Ac_eig = scipy.linalg.eigvals(Ac.toarray())\n",
    "test_vec = np.matmul(Ac.toarray(),sp.linalg.inv(Ag.toarray()))\n",
    "eig2 = scipy.linalg.eigvals(test_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "aborted",
     "timestamp": 1656897540523,
     "user": {
      "displayName": "Ru Huang",
      "userId": "03213243881794485520"
     },
     "user_tz": 240
    },
    "id": "cEq27usk280r"
   },
   "outputs": [],
   "source": [
    "Ag = solver_standard.levels[-1].A\n",
    "Ac = solver_non_galerkin.levels[-1].A\n",
    "\n",
    "# Ag_eig = scipy.linalg.eigvals(Ag.toarray())\n",
    "# Ac_eig = scipy.linalg.eigvals(Ac.toarray())\n",
    "test_vec = np.matmul(Ac.toarray(),sp.linalg.inv(Ag.toarray()))\n",
    "eig3 = scipy.linalg.eigvals(test_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "aborted",
     "timestamp": 1656897540524,
     "user": {
      "displayName": "Ru Huang",
      "userId": "03213243881794485520"
     },
     "user_tz": 240
    },
    "id": "2AOHIY4o29SL"
   },
   "outputs": [],
   "source": [
    "Ag = solver_standard.levels[-1].A\n",
    "Ac = solver_non_galerkin.levels[-1].A\n",
    "\n",
    "# Ag_eig = scipy.linalg.eigvals(Ag.toarray())\n",
    "# Ac_eig = scipy.linalg.eigvals(Ac.toarray())\n",
    "test_vec = np.matmul(Ac.toarray(),sp.linalg.inv(Ag.toarray()))\n",
    "eig4 = scipy.linalg.eigvals(test_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "aborted",
     "timestamp": 1656897540524,
     "user": {
      "displayName": "Ru Huang",
      "userId": "03213243881794485520"
     },
     "user_tz": 240
    },
    "id": "NAbaswnfCb2p"
   },
   "outputs": [],
   "source": [
    "# tt = np.identity(test_vec.shape[0])-test_vec\n",
    "# print(np.linalg.norm(tt,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "aborted",
     "timestamp": 1656897540524,
     "user": {
      "displayName": "Ru Huang",
      "userId": "03213243881794485520"
     },
     "user_tz": 240
    },
    "id": "u6iCmTIRG8X6"
   },
   "outputs": [],
   "source": [
    "print(len(eig4))\n",
    "print(len(eig3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "aborted",
     "timestamp": 1656897540525,
     "user": {
      "displayName": "Ru Huang",
      "userId": "03213243881794485520"
     },
     "user_tz": 240
    },
    "id": "t2T1Q1N2Snkt"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "t1 = np.linspace(1, len(eig1), len(eig1))\n",
    "t2 = np.linspace(1, len(eig1), len(eig2))\n",
    "t3 = np.linspace(1, len(eig1), len(eig3))\n",
    "t4 = np.linspace(1, len(eig1), len(eig4))\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "plt.plot(t1, np.sort(np.real(eig1)), 'r-',label='n=129')\n",
    "plt.plot(t2, np.sort(np.real(eig2)), 'g',label='n=65')\n",
    "plt.plot(t3, np.sort(np.real(eig3)), 'b--',label='n=33')\n",
    "plt.plot(t4, np.sort(np.real(eig4)), 'y+',label='n=17')\n",
    "\n",
    "plt.legend(fontsize=14)\n",
    "# plt.legend('errors H','errors jacobi')\n",
    "plt.ylabel('Eigenvalues',fontsize=18)\n",
    "plt.xlabel('Index',fontsize=18)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ax.set_xticks([15,30,45,60,75])\n",
    "# plt.plot(t, np.sort(np.real(Ag_eig)), 'r-',label=r'$A_{g}$')\n",
    "# # plt.plot(t, t2, 'g',label='Gauss-Siedel Smoother')\n",
    "# plt.plot(t, np.sort(np.real(Ac_eig)), 'b--',label=r'$A_{c}$')\n",
    "# plt.legend(fontsize=14)\n",
    "# # plt.legend('errors H','errors jacobi')\n",
    "# plt.ylabel('Eigenvalues',fontsize=18)\n",
    "# plt.xlabel('Index',fontsize=18)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "aborted",
     "timestamp": 1656897540525,
     "user": {
      "displayName": "Ru Huang",
      "userId": "03213243881794485520"
     },
     "user_tz": 240
    },
    "id": "looYCoG3l9mT"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "def heatmap2d(arr: np.ndarray,name):\n",
    "    plt.imshow(arr, cmap='viridis')\n",
    "    #plt.colorbar()\n",
    "    plt.axis('off')\n",
    "    # plt.savefig(name)\n",
    "    plt.show()\n",
    "heatmap2d(x1[0:test_grid_size*test_grid_size].reshape(test_grid_size,test_grid_size),'cylinder')\n",
    "heatmap2d(x1[test_grid_size*test_grid_size:].reshape(test_grid_size,test_grid_size),'cylinder')\n",
    "heatmap2d(x2[0:test_grid_size*test_grid_size].reshape(test_grid_size,test_grid_size),'cylinder')\n",
    "heatmap2d(x2[test_grid_size*test_grid_size:].reshape(test_grid_size,test_grid_size),'cylinder')\n",
    "# print(np.linalg.norm(x1[0:test_grid_size*test_grid_size].reshape(test_grid_size,test_grid_size)-x1[test_grid_size*test_grid_size:].reshape(test_grid_size,test_grid_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "aborted",
     "timestamp": 1656897540525,
     "user": {
      "displayName": "Ru Huang",
      "userId": "03213243881794485520"
     },
     "user_tz": 240
    },
    "id": "a44Zdm4MjeZv"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Copy of Thesis elasticity.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
